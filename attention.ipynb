{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qZJvhF0TrJmw"},"outputs":[],"source":["import torch\n","from matplotlib import pyplot as plt\n","def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n","                  cmap='Reds'):\n","    \"\"\"显示矩阵热图\"\"\"\n","    # plt.use_svg_display()\n","    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n","    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize,\n","                                 sharex=True, sharey=True, squeeze=False)\n","    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n","        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n","            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n","            if i == num_rows - 1:\n","                ax.set_xlabel(xlabel)\n","            if j == 0:\n","                ax.set_ylabel(ylabel)\n","            if titles:\n","                ax.set_title(titles[j])\n","    fig.colorbar(pcm, ax=axes, shrink=0.6);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEDeUeNBxnAT"},"outputs":[],"source":["# train_ch6所需的所有组件\n","import torch\n","from torch import nn\n","from IPython import display\n","import matplotlib.pyplot as plt\n","import time\n","import numpy as np\n","%matplotlib inline\n","import torchvision\n","from torch.utils import data\n","from torchvision import transforms\n","\n","def load_array(data_arrays, batch_size, is_train=True):\n","    dataset = data.TensorDataset(*data_arrays)\n","    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n","\n","# 更新器\n","def sgd(params, lr, batch):\n","    with torch.no_grad():\n","        for param in params:\n","            param -= lr * param.grad / batch_size\n","            param.grad.zero_()\n","\n","# 计时器\n","class Timer:\n","    def __init__(self):\n","        self.times = []\n","        self.start()\n","\n","    def start(self):\n","        self.tik = time.time()\n","\n","    def stop(self):\n","        self.times.append(time.time()-self.tik)\n","        return self.times[-1]\n","\n","    def avg(self):\n","        return sum(self.times)/len(self.times)\n","\n","    def sum(self):\n","        return sum(self.times)\n","\n","    def cumsum(self):\n","        return np.array(self.times).cumsum().tolist()\n","\n","\n","# 精准度的计算\n","def accuracy(y_hat, y):\n","    if len(y_hat.shape) \u003e 1 and y_hat.shape[1] \u003e 1:\n","        y_hat = y_hat.argmax(axis=1)\n","    cmp = y_hat.type(y.dtype) == y\n","    return float(cmp.type(y.dtype).sum())\n","\n","def evaluate_accuracy_gpu(net, data_iter, device=None):\n","    if isinstance(net, torch.nn.Module):\n","        net.eval()\n","        if not device:\n","          device = next(iter(net.parameters())).device\n","    metric = Accumulator(2)\n","    with torch.no_grad():\n","        for X, y in data_iter:\n","            if isinstance(X, list):\n","              # BERT微调所需\n","              X = [x.to(device) for x in X]\n","            else:\n","              X = X.to(device)\n","            y = y.to(device)\n","            metric.add(accuracy(net(X), y), y.numel())\n","    return metric[0] / metric[1]\n","\n","# 参数储存器\n","class Accumulator:\n","    def __init__(self, n):\n","        self.data = [0.0] * n\n","\n","    def add(self, *args):\n","        self.data = [a + float(b) for a, b in zip(self.data, args)]\n","\n","    def reset(self):\n","        self.data = [0.0] * len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","# 画图部分\n","def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n","    \"\"\"Set the axes for matplotlib.\"\"\"\n","    axes.set_xlabel(xlabel)\n","    axes.set_ylabel(ylabel)\n","    axes.set_xscale(xscale)\n","    axes.set_yscale(yscale)\n","    axes.set_xlim(xlim)\n","    axes.set_ylim(ylim)\n","    if legend:\n","        axes.legend(legend)\n","    axes.grid()\n","\n","class Animator:\n","    \"\"\"在动画中绘制数据\"\"\"\n","    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n","                 ylim=None, xscale='linear', yscale='linear',\n","                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n","                 figsize=(3.5, 2.5)):\n","        # 增量地绘制多条线\n","        if legend is None:\n","            legend = []\n","        # d2l.use_svg_display()\n","        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n","        if nrows * ncols == 1:\n","            self.axes = [self.axes, ]\n","        # 使用lambda函数捕获参数\n","        self.config_axes = lambda: set_axes(\n","            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n","        self.X, self.Y, self.fmts = None, None, fmts\n","\n","    def add(self, x, y):\n","        # 向图表中添加多个数据点\n","        if not hasattr(y, \"__len__\"):\n","            y = [y]\n","        n = len(y)\n","        if not hasattr(x, \"__len__\"):\n","            x = [x] * n\n","        if not self.X:\n","            self.X = [[] for _ in range(n)]\n","        if not self.Y:\n","            self.Y = [[] for _ in range(n)]\n","        for i, (a, b) in enumerate(zip(x, y)):\n","            if a is not None and b is not None:\n","                self.X[i].append(a)\n","                self.Y[i].append(b)\n","        self.axes[0].cla()\n","        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n","            self.axes[0].plot(x, y, fmt)\n","        self.config_axes()\n","        display.display(self.fig)\n","        display.clear_output(wait=True)\n","\n","# mini-batch取数据\n","def get_dataloader_workers():\n","  #使用四个线程\n","    return 4\n","\n","def load_data_fashion_mnist(batch_size, resize=None):\n","    trans = [transforms.ToTensor()]\n","    if resize:\n","        trans.insert(0, transforms.Resize(resize))\n","    trans = transforms.Compose(trans)\n","    mnist_train = torchvision.datasets.FashionMNIST(\n","        root=\"../data\", train=True, transform=trans, download=True)\n","    mnist_test = torchvision.datasets.FashionMNIST(\n","        root=\"../data\", train=False, transform=trans, download=True)\n","    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n","                            num_workers=get_dataloader_workers()), data.DataLoader(mnist_test, batch_size, shuffle=False,\n","                num_workers=get_dataloader_workers()))\n","\n","def try_gpu(i=0):\n","  \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n","  if torch.cuda.device_count() \u003e= i + 1:\n","        return torch.device(f'cuda:{i}')\n","  return torch.device('cpu')\n","\n","\n","  # 训练\n","def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n","    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n","    def init_weights(m):\n","        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n","            nn.init.xavier_uniform_(m.weight)\n","    net.apply(init_weights)\n","    print('training on', device)\n","    net.to(device)\n","    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n","    loss = nn.CrossEntropyLoss()\n","    animator = Animator(xlabel='epoch', xlim=[1, num_epochs],\n","                            legend=['train loss', 'train acc', 'test acc'])\n","    timer, num_batches = Timer(), len(train_iter)\n","    for epoch in range(num_epochs):\n","        # 训练损失之和，训练准确率之和，样本数\n","        metric = Accumulator(3)\n","        net.train()\n","        for i, (X, y) in enumerate(train_iter):\n","            timer.start()\n","            optimizer.zero_grad()\n","            X, y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","            l = loss(y_hat, y)\n","            l.backward()\n","            optimizer.step()\n","            with torch.no_grad():\n","                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n","            timer.stop()\n","            train_l = metric[0] / metric[2]\n","            train_acc = metric[1] / metric[2]\n","            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n","                animator.add(epoch + (i + 1) / num_batches,\n","                             (train_l, train_acc, None))\n","        test_acc = evaluate_accuracy_gpu(net, test_iter)\n","        animator.add(epoch + 1, (None, None, test_acc))\n","    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n","          f'test acc {test_acc:.3f}')\n","    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n","          f'on {str(device)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w49HphHayGgY"},"outputs":[],"source":["import torch\n","from torch import nn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-nO_E7F837Tu"},"outputs":[],"source":["# 注意力汇聚\n","def plot_kernel_reg(y_hat):\n","    # plt.plot(x_test, [y_truth, y_hat], 'x', 'y', legend=['Truth', 'Pred'],\n","    #          xlim=[0, 5], ylim=[-1, 5])\n","    plt.plot(x_test, y_truth, 'x', 'y')\n","    plt.plot(x_train, y_train, 'o', alpha=0.5);\n","\n","class NWKernelRegression(nn.Module):\n","  def __init__(self, **kwargs):\n","    super().__init__(**kwargs)\n","    self.w = nn.Parameter(torch.rand((1,), requires_grad=True))\n","\n","  def forward(self, queries, keys, values):\n","    queries = queries.repeat_interleave(keys.shape[1]).reshape((-1, keys.shape[1]))\n","    self.attention_weights = nn.functional.softmax(\n","        -0.5 * ((queries - keys) * self.w)**2, dim=1\n","    )\n","    return torch.bmm(self.attention_weights.unsqueeze(1),values.unsqueeze(-1)).reshape(-1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wez_-uDrXriH"},"outputs":[],"source":["# scoring function\n","def sequence_mask(X, valid_len, value=0):\n","    \"\"\"在序列中屏蔽不相关的项\"\"\"\n","    maxlen = X.size(1)\n","    mask = torch.arange((maxlen), dtype=torch.float32,\n","                        device=X.device)[None, :] \u003c valid_len[:, None]\n","    X[~mask] = value\n","    return X\n","\n","def masked_softmax(X, valid_lens):\n","  if valid_lens is None:\n","    return nn.functional.softmax(X, dim=-1)\n","  else:\n","    shape = X.shape\n","    if valid_lens.dim()==1:\n","      valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n","    else:\n","      valid_lens = valid_lens.reshape(-1)\n","    X = sequence_mask(X.reshape(-1, X.shape[-1]), valid_lens, value=-1e6)\n","    return nn.functional.softmax(X.reshape(shape), dim=-1)\n","\n","class AdditiveAttention(nn.Module):\n","  def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n","    super(AdditiveAttention, self).__init__(**kwargs)\n","    self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n","    self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n","    self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, queries, keys, values, valid_lens):\n","    queries, keys = self.W_q(queries), self.W_k(keys)\n","    features = queries.unsqueeze(2) + keys.unsqueeze(1)\n","    features = torch.tanh(features)\n","    scores = self.w_v(features).squeeze(-1)\n","    self.attention_weights = masked_softmax(scores, valid_lens)\n","    return torch.bmm(self.dropout(self.attention_weights), values)\n","\n","import math\n","class DotProductAttention(nn.Module):\n","  def __init__(self, dropout, **kwargs):\n","    super(DotProductAttention, self).__init__(**kwargs)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, queries, keys, values, valid_lens=None):\n","    d = queries.shape[-1]\n","    scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n","    self.attention_weights = masked_softmax(scores, valid_lens)\n","    return torch.bmm(self.dropout(self.attention_weights), values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1KNC2AUjaWR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19597,"status":"ok","timestamp":1693624375295,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"g8k_oDWGAXGF","outputId":"c461e8d2-d93c-4840-e7c7-585f28365cc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcfcturaihwo"},"outputs":[],"source":["# 文本处理组件\n","import torch\n","# from d2l import torch as d2l\n","import collections\n","import re\n","# from d2l import torch as d2l\n","\n","class Vocab:\n","    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n","        if tokens==None:\n","            tokens = []\n","        if reserved_tokens==None:\n","            reserved_tokens = []\n","#         按出现频率排序\n","        counter = count_corpus(tokens)\n","        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n","                                  reverse=True)\n","        self.idx_to_token = ['\u003cunk\u003e'] + reserved_tokens\n","        self.token_to_idx = {token: idx for idx, token in\n","                           enumerate(self.idx_to_token)}\n","        for token, freq in self._token_freqs:\n","            if freq \u003c min_freq:\n","                break\n","            if token not in self.token_to_idx:\n","                self.idx_to_token.append(token)\n","                self.token_to_idx[token] = len(self.idx_to_token) - 1\n","\n","    def __len__(self):\n","        return len(self.idx_to_token)\n","\n","    def __getitem__(self, tokens):\n","        if not isinstance(tokens, (list, tuple)):\n","            return self.token_to_idx.get(tokens, self.unk)\n","        return [self.__getitem__(token) for token in tokens]\n","\n","    def to_tokens(self, indices):\n","        if not isinstance(indices, (list, tuple)):\n","            return self.idx_to_token[indices]\n","        return [self.idx_to_token[index] for index in indices]\n","\n","    @property\n","    def unk(self):\n","        return 0\n","\n","    @property\n","    def token_freqs(self):\n","        return self._token_freqs\n","\n","\n","\n","def count_corpus(tokens):\n","    # 这里的tokens是1D列表或2D列表\n","    if len(tokens) == 0 or isinstance(tokens[0], list):\n","        tokens = [token for line in tokens for token in line]\n","    return collections.Counter(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npKdmSt7NmN5"},"outputs":[],"source":["# 9.5 机器翻译与数据集\n","def read_data_nmt():\n","  with open('/content/drive/MyDrive/fra.txt', 'r', encoding='utf-8') as f:\n","    return f.read()\n","\n","def preprocess_nmt(text):\n","    \"\"\"预处理“英语－法语”数据集\"\"\"\n","    def no_space(char, prev_char):\n","        return char in set(',.!?') and prev_char != ' '\n","\n","    # 使用空格替换不间断空格\n","    # 使用小写字母替换大写字母\n","    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n","    # 在单词和标点符号之间插入空格\n","    out = [' ' + char if i \u003e 0 and no_space(char, text[i - 1]) else char\n","           for i, char in enumerate(text)]\n","    return ''.join(out)\n","\n","def tokenize_nmt(text, num_examples=None):\n","  source, target = [], []\n","  for i, line in enumerate(text.split('\\n')):\n","    if num_examples and i \u003e num_examples:\n","      break\n","    parts = line.split('\\t')\n","    if len(parts) == 2:\n","      source.append(parts[0].split(' '))\n","      target.append(parts[1].split(' '))\n","  return source, target\n","\n","from matplotlib import pyplot as plt\n","def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n","    \"\"\"绘制列表长度对的直方图\"\"\"\n","    # plt.set_figsize()\n","    plt.figure(figsize=(8,5), dpi=80)\n","    _, _, patches = plt.hist(\n","        [[len(l) for l in xlist], [len(l) for l in ylist]])\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    for patch in patches[1].patches:\n","        patch.set_hatch('/')\n","    plt.legend(legend)\n","\n","def truncate_pad(line, num_steps, padding_token):\n","    \"\"\"截断或填充文本序列\"\"\"\n","    if len(line) \u003e num_steps:\n","        return line[:num_steps]  # 截断\n","    return line + [padding_token] * (num_steps - len(line))  # 填充\n","\n","def build_array_nmt(lines, vocab, num_steps):\n","    \"\"\"将机器翻译的文本序列转换成小批量\"\"\"\n","    lines = [vocab[l] for l in lines]\n","    lines = [l + [vocab['\u003ceos\u003e']] for l in lines]\n","    array = torch.tensor([truncate_pad(\n","        l, num_steps, vocab['\u003cpad\u003e']) for l in lines])\n","    valid_len = (array != vocab['\u003cpad\u003e']).type(torch.int32).sum(1)\n","    return array, valid_len\n","\n","def load_data_nmt(batch_size, num_steps, num_examples=600):\n","    \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n","    text = preprocess_nmt(read_data_nmt())\n","    source, target = tokenize_nmt(text, num_examples)\n","    src_vocab = Vocab(source, min_freq=2,\n","                          reserved_tokens=['\u003cpad\u003e', '\u003cbos\u003e', '\u003ceos\u003e'])\n","    tgt_vocab = Vocab(target, min_freq=2,\n","                          reserved_tokens=['\u003cpad\u003e', '\u003cbos\u003e', '\u003ceos\u003e'])\n","    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n","    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n","    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n","    data_iter = load_array(data_arrays, batch_size)\n","    return data_iter, src_vocab, tgt_vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrGiox7lNLvu"},"outputs":[],"source":["# 9.6 编码器-解码器架构\n","from torch import nn\n","\n","class Encoder(nn.Module):\n","  def __init__(self, **kwargs):\n","    super(Encoder, self).__init__(**kwargs)\n","\n","  def forward(self, X, *args):\n","    raise NotImplementedError\n","\n","class Decoder(nn.Module):\n","  def __init__(self, **kwargs):\n","    super(Decoder, self).__init__(**kwargs)\n","\n","  def init_state(self, enc_outputs, *args):\n","    raise NotImplementedError\n","\n","  def forward(self, X, state):\n","    raise NotImplementedError\n","\n","class EncoderDecoder(nn.Module):\n","  def __init__(self, encoder, decoder, **kwargs):\n","    super(EncoderDecoder, self).__init__(**kwargs)\n","    self.encoder = encoder\n","    self.decoder = decoder\n","\n","  def forward(self, enc_X, dec_X, *args):\n","    enc_outputs = self.encoder(enc_X, *args)\n","    dec_state = self.decoder.init_state(enc_outputs, *args)\n","    return self.decoder(dec_X, dec_state)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7_xuz_Y7F_bN"},"outputs":[],"source":["# 9.7 seq2seq实现\n","def grad_clipping(net, theta):\n","    \"\"\"裁剪梯度\"\"\"\n","    if isinstance(net, nn.Module):\n","        params = [p for p in net.parameters() if p.requires_grad]\n","    else:\n","        params = net.params\n","    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n","    if norm \u003e theta:\n","        for param in params:\n","            param.grad[:] *= theta / norm\n","\n","class Seq2SeqEncoder(Encoder):\n","  def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n","               dropout=0, **kwargs):\n","    super(Seq2SeqEncoder, self).__init__(**kwargs)\n","    self.embedding = nn.Embedding(vocab_size, embed_size)\n","    self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)\n","\n","  def forward(self, X, *args):\n","    X = self.embedding(X).permute(1, 0, 2)\n","    output, state = self.rnn(X)\n","    return output, state\n","\n","class Seq2SeqDecoder(Decoder):\n","    \"\"\"用于序列到序列学习的循环神经网络解码器\"\"\"\n","    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n","                 dropout=0, **kwargs):\n","        super(Seq2SeqDecoder, self).__init__(**kwargs)\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n","                          dropout=dropout)\n","        self.dense = nn.Linear(num_hiddens, vocab_size)\n","\n","    def init_state(self, enc_outputs, *args):\n","        return enc_outputs[1]\n","\n","    def forward(self, X, state):\n","        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n","        X = self.embedding(X).permute(1, 0, 2)\n","        # 广播context，使其具有与X相同的num_steps\n","        context = state[-1].repeat(X.shape[0], 1, 1)\n","        X_and_context = torch.cat((X, context), 2)\n","        output, state = self.rnn(X_and_context, state)\n","        output = self.dense(output).permute(1, 0, 2)\n","        # output的形状:(batch_size,num_steps,vocab_size)\n","        # state的形状:(num_layers,batch_size,num_hiddens)\n","        return output, state\n","\n","def sequence_mask(X, valid_len, value=0):\n","    \"\"\"在序列中屏蔽不相关的项\"\"\"\n","    maxlen = X.size(1)\n","    mask = torch.arange((maxlen), dtype=torch.float32,\n","                        device=X.device)[None, :] \u003c valid_len[:, None]\n","    X[~mask] = value\n","    return X\n","\n","class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n","    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n","    # pred的形状：(batch_size,num_steps,vocab_size)\n","    # label的形状：(batch_size,num_steps)\n","    # valid_len的形状：(batch_size,)\n","    def forward(self, pred, label, valid_len):\n","        weights = torch.ones_like(label)\n","        weights = sequence_mask(weights, valid_len)\n","        self.reduction='none'\n","        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n","            pred.permute(0, 2, 1), label)\n","        # print(unweighted_loss.shape)\n","        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n","        return weighted_loss\n","\n","def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n","  def xavier_init_weights(m):\n","    if type(m) == nn.Linear:\n","      nn.init.xavier_uniform_(m.weight)\n","    if type(m) == nn.GRU:\n","      for param in m._flat_weights_names:\n","        if \"weight\" in param:\n","          nn.init.xavier_uniform_(m._parameters[param])\n","\n","  net.apply(xavier_init_weights)\n","  net.to(device)\n","  optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","  loss = MaskedSoftmaxCELoss()\n","  net.train()\n","  animator = Animator(xlabel='epoch', ylabel='loss',\n","                     xlim=[10, num_epochs])\n","  for epoch in range(num_epochs):\n","    timer = Timer()\n","    metric = Accumulator(2)\n","    for batch in data_iter:\n","      optimizer.zero_grad()\n","      X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n","      bos = torch.tensor([tgt_vocab['\u003cbos\u003e']] * Y.shape[0],\n","                         device=device).reshape(-1, 1)\n","      dec_input = torch.cat([bos, Y[:, :-1]], 1)\n","      Y_hat, _ = net(X, dec_input, X_valid_len)\n","      l = loss(Y_hat, Y, Y_valid_len)\n","      l.sum().backward()\n","      grad_clipping(net, 1)\n","      num_tokens = Y_valid_len.sum()\n","      optimizer.step()\n","      with torch.no_grad():\n","        metric.add(l.sum(), num_tokens)\n","    if (epoch + 1) % 10 == 0:\n","            animator.add(epoch + 1, (metric[0] / metric[1],))\n","  print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n","        f'tokens/sec on {str(device)}')\n","\n","def predict_seq2seq(net, src_sentences, src_vocab, tgt_vocab,\n","                    num_steps, device, save_attention_weights=False):\n","  net.eval()\n","  src_tokens = src_vocab[src_sentences.lower().split(' ')] + [src_vocab['\u003ceos\u003e']]\n","  enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n","  src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['\u003cpad\u003e'])\n","  # 添加批量轴\n","  enc_X = torch.unsqueeze(\n","      torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0\n","  )\n","  enc_outputs = net.encoder(enc_X, enc_valid_len)\n","  dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n","  dec_X = torch.unsqueeze(\n","      torch.tensor([tgt_vocab['\u003cbos\u003e']], dtype=torch.long, device=device), dim=0\n","  )\n","  output_seq, attention_weight_seq = [], []\n","  for _ in range(num_steps):\n","    Y, dec_state = net.decoder(dec_X, dec_state)\n","    dec_X = Y.argmax(dim=2)\n","    # print(f'shape of Y is {Y.shape}, shape of dec_X is {dec_X.shape}')\n","    pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n","    # print(f'pred is {pred},pred before is {dec_X.squeeze(dim=0).type(torch.int32)}')\n","    if save_attention_weights:\n","        attention_weight_seq.append(net.decoder.attention_weights)\n","        # 一旦序列结束词元被预测，输出序列的生成就完成了\n","    if pred == tgt_vocab['\u003ceos\u003e']:\n","        break\n","    output_seq.append(pred)\n","  return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n","\n","def bleu(pred_seq, label_seq, k):\n","    \"\"\"计算BLEU\"\"\"\n","    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n","    len_pred, len_label = len(pred_tokens), len(label_tokens)\n","    score = math.exp(min(0, 1 - len_label / len_pred))\n","    for n in range(1, k + 1):\n","        num_matches, label_subs = 0, collections.defaultdict(int)\n","        for i in range(len_label - n + 1):\n","            label_subs[' '.join(label_tokens[i: i + n])] += 1\n","        for i in range(len_pred - n + 1):\n","            if label_subs[' '.join(pred_tokens[i: i + n])] \u003e 0:\n","                num_matches += 1\n","                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n","        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUetcWNOJJyu"},"outputs":[],"source":["class AdditiveAttention(nn.Module):\n","  def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n","    super(AdditiveAttention, self).__init__(**kwargs)\n","    self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n","    self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n","    self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, queries, keys, values, valid_lens):\n","    queries, keys = self.W_q(queries), self.W_k(keys)\n","    features = queries.unsqueeze(2) + keys.unsqueeze(1)\n","    features = torch.tanh(features)\n","    scores = self.w_v(features).squeeze(-1)\n","    self.attention_weights = masked_softmax(scores, valid_lens)\n","    return torch.bmm(self.dropout(self.attention_weights), values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCZZie2OAEa7"},"outputs":[],"source":["# 10.4 Bahdanau注意力模型\n","class AttentionDecoder(Decoder):\n","  def __init__(self, **kwargs):\n","    super(AttentionDecoder, self).__init__(**kwargs)\n","\n","  @property\n","  def attention_weights(self):\n","    raise NotImplementedError\n","\n","class Seq2SeqLSTMEncoder(Encoder):\n","  def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n","               dropout=0, **kwargs):\n","    super(Seq2SeqLSTMEncoder, self).__init__(**kwargs)\n","    self.embedding = nn.Embedding(vocab_size, embed_size)\n","    self.rnn = nn.LSTM(embed_size, num_hiddens, num_layers, dropout=dropout)\n","\n","  def forward(self, X, *args):\n","    X = self.embedding(X).permute(1, 0, 2)\n","    output, state = self.rnn(X)\n","    return output, state\n","\n","class Seq2SeqAttentionDecoder(AttentionDecoder):\n","    \"\"\"用于序列到序列学习的循环神经网络解码器\"\"\"\n","    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n","                 dropout=0, **kwargs):\n","        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n","        self.attention = AdditiveAttention(\n","            num_hiddens,num_hiddens, num_hiddens, dropout\n","        )\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.rnn = nn.LSTM(embed_size + num_hiddens, num_hiddens, num_layers,\n","                          dropout=dropout)\n","        self.dense = nn.Linear(num_hiddens, vocab_size)\n","\n","    def init_state(self, enc_outputs, enc_valid_lens, *args):\n","        outputs, hidden_state = enc_outputs\n","        return (outputs.permute(1, 0, 2), (hidden_state, hidden_state), enc_valid_lens)\n","\n","    def forward(self, X, state):\n","        enc_outputs, hidden_state, enc_valid_lens = state\n","        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n","        X = self.embedding(X).permute(1, 0, 2)\n","        outputs, self._attention_weights = [], []\n","        for x in X:\n","          query = torch.unsqueeze(hidden_state[0][-1], dim=1)\n","          context = self.attention(\n","              query, enc_outputs, enc_outputs, enc_valid_lens\n","          )\n","          x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n","          out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n","          outputs.append(out)\n","          self._attention_weights.append(self.attention.attention_weights)\n","        # 全连接层变换后，outputs的形状为\n","        # (num_steps,batch_size,vocab_size)\n","        outputs = self.dense(torch.cat(outputs, dim=0))\n","        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n","                                          enc_valid_lens]\n","\n","    @property\n","    def attention_weights(self):\n","        return self._attention_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":615,"status":"ok","timestamp":1693104156945,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"QLIJzA5tRRnl","outputId":"685a69ae-b503-4d1e-9297-60eb7960a842"},"outputs":[{"data":{"text/plain":["(torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([2, 4, 16]))"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n","                             num_layers=2)\n","encoder.eval()\n","decoder = Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n","                                  num_layers=2)\n","decoder.eval()\n","X = torch.zeros((4, 7), dtype=torch.long)  # (batch_size,num_steps)\n","state = decoder.init_state(encoder(X), None)\n","output, state = decoder(X, state)\n","output.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"elapsed":75592,"status":"ok","timestamp":1693104235194,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"wSrpHjSbSyY1","outputId":"a023364c-1cc7-4f59-ed63-0dd4e7e629b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["loss 0.022, 7453.7 tokens/sec on cuda:0\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWwAAAD/CAYAAADVGuzgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxBUlEQVR4nO3de1xUdfoH8M+ZYZhhuN9vgsNFxRtgXgivlQh42TLdMmtXM9PNctvCrGhLU9swNdd1s9w0zXYrrTQrLX4iCd4QFCVvqIAgCgyX4TLAwMzAfH9/IGMjiAgzHGZ83q8XL4dzzhyexxk/HL/nzPdwjDEGQgghvZ6A7wIIIYR0DgU2IYSYCQpsQggxExTYhBBiJiiwCSHETFBgE0KImaDAJoQQM2HFdwG9kU6nQ3FxMezt7cFxHN/lEELMBGMMtbW18PHxgUBg/ONhCux2FBcXw8/Pj+8yCCFm6vr16+jTp4/R90uB3Q57e3sALX/pDg4OPFfTOVqtFgcOHEB0dDREIhHf5ZiEpfdo6f0Blt9jZWUlAgIC9BlibBTY7WgdBnFwcDCrwJZKpXBwcLDIfwiA5fdo6f0Blt+jVqsFAJMNpdJJR0IIMRMU2IQQYiYosAkhxExQYBNCiJmgwCaEEDNBgd0BdVMz3yUQQogeBXYHfius4bsEQgjRo8DuQNrVCr5LIIQQPQrsDqTlKfgugRBC9CiwO3ChRImqeg3fZRBCCAAK7A4xBhyno2xCSC9BgX0XR3PL+S6BEEIAUGDf1eErFWCM8V0GIYRQYHdEJORQVN2AAoWK71IIIYQCuyNhfZwAAEdzaFiEEMI/CuwOjA52BQAcyaHrsQkh/KPA7kBkYEtgp+Up0NSs47kaQsj9jgK7A4N8HOFoI0Ktugm/3aCPqRNC+EWB3QGhgMMY/bAIjWMTQvhFgX0X4/q5AwCO0jg2IYRnFNh3MTbYDQBw5no1ahu1PFdDCLmfUWDfhZ+LFDJXKZp1DCeuVvJdDiHkPkaB3Qlj+7UcZdM4NiGETxTYnUDj2ISQ3oACuxMig1whFHC4WlGPouoGvsshhNynKLA7wUEiQlgfRwD0MXVCCH8osDtp7M1hkcM0LEII4QkFdieNv3ni8XhuBXQ6mm6VENLzKLA7KczPCXZiK1SptLhQrOS7HELIfYgCu5NEQgEevDkZ1BG6Cw0hhAcU2PdgXOv12FdoHJsQ0vMosO9Ba2BnXqtCg6aZ52oIIfcbCux7EOBmC18nG2iadUjPp7upE0J6Vq8I7E2bNkEmk0EikSAiIgIZGRl33HbLli0YN24cnJ2d4ezsjKioqDbbM8awbNkyeHt7w8bGBlFRUcjJyel2nRzH6SeDok89EkJ6Gu+BvWvXLsTFxWH58uU4ffo0wsLCEBMTg7Kysna3T0lJwezZs3Ho0CGkpaXBz88P0dHRKCoq0m+zZs0abNy4EZs3b0Z6ejpsbW0RExODxsbGbtd7a14RCmxCSM/iPbDXr1+PBQsWYN68eRg0aBA2b94MqVSKbdu2tbv9l19+iRdffBHh4eEICQnB1q1bodPpkJycDKDl6HrDhg14++238dhjjyE0NBRffPEFiouLsXfv3m7XOybYDRwHXC6tRZmy+78ACCGks6z4/OEajQaZmZmIj4/XLxMIBIiKikJaWlqn9qFSqaDVauHi4gIAyM/Ph1wuR1RUlH4bR0dHREREIC0tDU899VSbfajVaqjVav33SmXLddZarRZareEc2PbWHAZ7O+B8sRKpl0sxPdyn8w2bUGudt9drSSy9R0vvD7D8Hk3dF6+BXVFRgebmZnh6ehos9/T0xKVLlzq1jzfeeAM+Pj76gJbL5fp93L7P1nW3S0hIwIoVK9osP3DgAKRSaZvlXhDgPAT4JvUsrIuzOlVnT0lKSuK7BJOz9B4tvT/AcntUqVQm3T+vgd1dq1evxs6dO5GSkgKJRNLl/cTHxyMuLk7/vVKp1I+NOzg4tNne+aoCB7dnoqBRgsmTJ4DjuC7/bGPRarVISkrCpEmTIBKJ+C7HJCy9R0vvD7D8HhUK0149xmtgu7m5QSgUorS01GB5aWkpvLy8OnzuunXrsHr1ahw8eBChoaH65a3PKy0thbe3t8E+w8PD292XWCyGWCxus1wkErX7pooIcodEJEB5nQZXKxsR4tU21Plyp5otiaX3aOn9AZbbo6l74vWko7W1NYYPH64/YQhAfwIxMjLyjs9bs2YNVq1ahcTERIwYMcJgXUBAALy8vAz2qVQqkZ6e3uE+74XYSoiIgJaPqdPlfYSQnsL7VSJxcXHYsmULduzYgezsbCxatAj19fWYN28eAGDOnDkGJyU/+OADvPPOO9i2bRtkMhnkcjnkcjnq6uoAtFwr/corr+C9997Djz/+iHPnzmHOnDnw8fHB9OnTjVb3OLq8jxDSw3gfw541axbKy8uxbNkyyOVyhIeHIzExUX/SsLCwEALBrd8rn3zyCTQaDf74xz8a7Gf58uV49913AQCvv/466uvrsXDhQlRXV2Ps2LFITEzs1jj37Vqvx07PV0Dd1AyxldBo+yaEkPbwHtgAsHjxYixevLjddSkpKQbfFxQU3HV/HMdh5cqVWLlypRGqa98AT3u424tRXqtGZkEVRt/8BCQhhJgK70Mi5orjOIy7GdJHcmlYhBBiehTY3dA6LEInHgkhPYECuxtaJ4I6X1yDynoNz9UQQiwdBXY3eDhIMMDTHowBydmld38CIYR0AwV2Nz16cy6Rz47mgzG6OS8hxHQosLvpTxF9IbUW4pK8FqlX6F6PhBDTocDuJkepCLNH+QMA/pN6ledqCCGWjALbCOaPDYCVgEPaVQV+u17NdzmEEAtFgW0EPk42+rHs/xzO47kaQoilosA2kr+MDwIA/HJejoKKep6rIYRYIgpsIxngZY9HQjzAGPDpERrLJoQYHwW2Ef1lfCAA4LvMGyivVd9la0IIuTcU2EY0KsAF4X5O0DTpsON4Ad/lEEIsDAW2EXEchxcmtIxlf5FWgDp1E88VEUIsCQW2kU0a5IlAN1soG5uwM6OQ73IIIRaEAtvIhAIOC2+OZX92NB+aJh3PFRFCLAUFtglMH+YLd3sxSmoa8dNvxXyXQwixEBTYJiARCTFvjAxAywdpaFIoQogxUGCbyDMRfWEntsKV0joculzGdzmEEAtAgW0ijjYiPB3RMinUZpoUihBiBBTYJvTcmACIhBwy8itxurCK73IIIWaOAtuEvBwlmB7uCwD4TypNCkUI6R4KbBP7y4SWS/wOXCxFXnkdz9UQQswZBbaJBXvYI2qgJxgDttKkUISQbqDA7gEv3DzK3p1ZhDJlI8/VEELMFQV2Dxghc8Hwvs7QNOuwnSaFIoR0EQV2D2mdFOp/J66htlHLczWEEHNEgd1DJoZ4INjDDrWNTfgynSaFIoTcOwrsHiIQcPobHHySkodqlYbniggh5oYCuwc9PswXAzztUdOgxb+Sc/guhxBiZngP7E2bNkEmk0EikSAiIgIZGRl33PbChQuYOXMmZDIZOI7Dhg0b2mzz7rvvguM4g6+QkBATdtB5VkIB3p42EADw37RrdF02IeSe8BrYu3btQlxcHJYvX47Tp08jLCwMMTExKCtrf7IklUqFwMBArF69Gl5eXnfc7+DBg1FSUqL/Onr0qKlauGfj+rnjkRAPNOkYEn7O5rscQogZseLzh69fvx4LFizAvHnzAACbN2/G/v37sW3bNrz55pttth85ciRGjhwJAO2ub2VlZdVhoN9OrVZDrb5101ylUgkA0Gq10GqNf0XH69H9cPhKOQ5mlyH1khyjg1y7vc/WOk1Rb29h6T1aen+A5fdo6r54C2yNRoPMzEzEx8frlwkEAkRFRSEtLa1b+87JyYGPjw8kEgkiIyORkJAAf3//O26fkJCAFStWtFl+4MABSKXSbtVyJ6M9BDgsFyD+m1NYGtoMAWec/SYlJRlnR72Ypfdo6f0BltujSqUy6f55C+yKigo0NzfD09PTYLmnpycuXbrU5f1GRETg888/x4ABA1BSUoIVK1Zg3LhxOH/+POzt7dt9Tnx8POLi4vTfK5VK+Pn5ITo6Gg4ODl2upSORKg0mbTiKYlUTVJ6heHJEn27tT6vVIikpCZMmTYJIJDJSlb2Lpfdo6f0Blt+jQqEw6f55HRIxhcmTJ+sfh4aGIiIiAn379sU333yD+fPnt/scsVgMsVjcZrlIJDLZm8rDUYSXJ/bHqn0X8c/kPDz2gB/sxN1/OUxZc29h6T1aen+A5fZo6p54O+no5uYGoVCI0tJSg+WlpaX3NP58N05OTujfvz9yc3ONtk9j+fODfRHgZouKOjU+PtT76iOE9C68Bba1tTWGDx+O5ORk/TKdTofk5GRERkYa7efU1dUhLy8P3t7eRtunsVhbCRA/ueWSw61H83G90rTjX4QQ88brZX1xcXHYsmULduzYgezsbCxatAj19fX6q0bmzJljcFJSo9EgKysLWVlZ0Gg0KCoqQlZWlsHR82uvvYbU1FQUFBTg+PHjePzxxyEUCjF79uwe768zJg3yRGSgKzRNOnyQ2PWxe0KI5eN1DHvWrFkoLy/HsmXLIJfLER4ejsTERP2JyMLCQggEt36nFBcXY9iwYfrv161bh3Xr1mHChAlISUkBANy4cQOzZ8+GQqGAu7s7xo4dixMnTsDd3b1He+ssjuPw9rSBmPbvo9h3tgTzxlRieF8XvssihPRCvJ90XLx4MRYvXtzuutYQbiWTycAY63B/O3fuNFZpPWawjyOeHO6HXaeuY+W+bHy/aDQExrrOjxBiMbo0JLJjxw7s379f//3rr78OJycnjB49GteuXTNacfeTJTH9YWstxG/Xq/HT2WK+yyGE9EJdCuz3338fNjY2AIC0tDRs2rQJa9asgZubG1599VWjFni/8LCX4MWHgwEAH/xyCQ2aZp4rIoT0Nl0K7OvXryM4uCVc9u7di5kzZ2LhwoVISEjAkSNHjFrg/WT+2AD4OtmguKaR7v9ICGmjS4FtZ2en/0TPgQMHMGnSJACARCJBQ0OD8aq7z0hEQrweOwAA8ElqHkrp/o+EkN/pUmBPmjQJzz//PJ5//nlcuXIFU6ZMAdAy/alMJjNmffedR8N8MMzfCSpNM9b932W+yyGE9CJdCuxNmzYhMjIS5eXl2L17N1xdW2aby8zM7LXXO5sLjuPwzrRBAIDvTt/A+aIanisihPQWXbqsz8nJCR999FGb5e3NeEfu3QP+zng0zAc//laMlT9dxM6FD9JlfoSQrh1hJyYmGtwUYNOmTQgPD8fTTz+NqqoqoxV3P3tjcggkIgEyCiqx9SidgCSEdDGwly5dqp/k/9y5c1iyZAmmTJmC/Px8g2lKSdf5Otlg2bTBAIC1/3cZ527Q0Agh97suBXZ+fj4GDWoZZ929ezemTZuG999/H5s2bcIvv/xi1ALvZ7NH+SF2sBe0zQwv7zyDenUT3yURQnjUpcC2trbW31nh4MGDiI6OBgC4uLjoj7xJ93Ech9Uzh8LbUYL8inos//EC3yURQnjUpcAeO3Ys4uLisGrVKmRkZGDq1KkAgCtXrqBPn+7dOYUYcpJaY8OscAg44LvMG/jxN/rYOiH3qy4F9kcffQQrKyt89913+OSTT+Dr6wsA+OWXXxAbG2vUAgkQEeiKxTc/tv73Pedo3mxC7lNduqzP398f+/bta7P8n//8Z7cLIu17eWI/HMtTIPNaFf628wy++UskrIS8TmdOCOlhXZ5etbm5GXv37kV2djYAYPDgwXj00UchFAqNVhy5xUoowIZZ4Ziy8QhOF1ZjY3IO4qIH8F0WIaQHdekQLTc3FwMHDsScOXOwZ88e7NmzB3/6058wePBg5OXlGbtGcpOfixTvPz4UAPDRoVykXzXtHZoJIb1LlwL75ZdfRlBQEK5fv47Tp0/j9OnTKCwsREBAAF5++WVj10h+5w9hPnhieB/oGPDKrixUqzR8l0QI6SFdCuzU1FSsWbMGLi63bmXl6uqK1atXIzU11WjFkfa9++hgBLjZoqSmEW/uPnfXu/AQQixDlwJbLBajtra2zfK6ujpYW1t3uyjSMVuxFTY+NQwiIYfEC3J8nXGd75IIIT2gS4E9bdo0LFy4EOnp6WCMgTGGEydO4IUXXsCjjz5q7BpJO4b2ccTSmJaTjiv3XUBOWR3PFRFCTK1Lgb1x40YEBQUhMjISEokEEokEo0ePRnBwMDZs2GDkEsmdPD82EOP6uaFRq0PcN2eh1fFdESHElLo8veoPP/yA3Nxc/WV9AwcO1N82jPQMgYDDh0+GYfKGI7hUWocfOQEe47soQojJdDqw7zYL36FDh/SP169f3/WKyD3xsJdg3RNhmPf5SRyWC/D9mWI8Oaov32URQkyg04F95syZTm3HcTTRfk97OMQDC8fJ8OmRAsTvvQBnOwkmDfLkuyxCiJF1OrB/fwRNep8lUf2QdekqMsoFeOmr09gxbxQig1z5LosQYkQ0GYWFEAg4PBWkQ1SIOzRNOiz44hTd9IAQC0OBbUGEHLDhyVBEBrqiTt2EudszkEuX+xFiMSiwLYxYJMSnc4ZjqK8jKus1mPNZOoqqG/guixBiBBTYFsheIsLn80YiyN0WxTWN+PNn6VDUqfkuixDSTbwH9qZNmyCTySCRSBAREYGMjIw7bnvhwgXMnDkTMpkMHMfd8UM697JPS+VqJ8Z/50fAx1GCq+X1mLs9A7WNWr7LIoR0A6+BvWvXLsTFxWH58uU4ffo0wsLCEBMTg7Kysna3V6lUCAwMxOrVq+Hl5WWUfVoyHycb/Pf5CLjaWuN8kRLP7ziFRm0z32URQrqI18Bev349FixYgHnz5mHQoEHYvHkzpFIptm3b1u72I0eOxNq1a/HUU09BLBYbZZ+WLsjdDjueGwU7sRXS8yux+KvT0DbTZ9gJMUddvuNMd2k0GmRmZiI+Pl6/TCAQICoqCmlpaT26T7VaDbX61hhv653ftVottFrzGEZorbO9egd4SLH5mXDM/+I0DmaXYek3WfhgxhAIBOb1IaeOerQElt4fYPk9mrov3gK7oqICzc3N8PQ0/ESep6cnLl261KP7TEhIwIoVK9osP3DgAKRSaZdq4UtSUtId180J4vDZZQH2/laCytIizJDpYI4fTO2oR0tg6f0BltujSmXaG2TzFti9SXx8vMFcKUqlEn5+foiOjoaDgwOPlXWeVqtFUlISJk2aBJFI1O42UwD0zyrG0t3ncVguQHBgAN6I6W82R9qd6dGcWXp/gOX3qFCY9rZ9vAW2m5sbhEIhSktLDZaXlpbe8YSiqfYpFovbHRMXiURm96a6W81PjOyLeo0O7/50EduOX4O8Vo31T4ZDIjKfmyeb4+tyLyy9P8ByezR1T7yddLS2tsbw4cORnJysX6bT6ZCcnIzIyMhes09L9OyYAGyYFQ6RkMPP5+R4Zms6Kuvp3pCE9Ha8XiUSFxeHLVu2YMeOHcjOzsaiRYtQX1+PefPmAQDmzJljcAJRo9EgKysLWVlZ0Gg0KCoqQlZWFnJzczu9T9Ji+jBffPFcBBwkVsi8VoUZHx9DQUU932URQjrA6xj2rFmzUF5ejmXLlkEulyM8PByJiYn6k4aFhYUQCG79TikuLsawYcP0369btw7r1q3DhAkTkJKS0ql9klsig1yx58XReHb7SRQoVHj842PYOncEhvd1ufuTCSE9jveTjosXL8bixYvbXdcawq1kMlmn7hDe0T6JoWAPe+x5cTSe33EKZ2/UYPaWdGyYFY4pQ735Lo0QchveP5pO+OdhL8HOhQ8iaqAHNE06vPjlaXx6OK9TvxwJIT2HApsAAKTWVvjPn0dgbmTL7cXe//kSlv1wAU30qUhCeg0KbKInFHB499HBeHvqQHAc8N8T1/CX/2ZCpWniuzRCCCiwyW04jsPz4wLx8dMPQGwlQPKlMsz6zwmU1TbyXRoh9z0KbNKuyUO98dWCB+Fia41zRTWYuvEofr1UevcnEkJMhgKb3NHwvs7Ys2g0gj3sUF6rxnOfn8Kbu8+iTk1DJITwgQKbdEjmZot9fx2L+WMDwHHAzpPXEbvhME5cNe2cCYSQtiiwyV1JREK8M20Qvnr+Qfg62eBGVQNmbzmB9/ZdpBsiENKDKLBJp0UGuSLxlXGYNcIPjAFbj+Zj2r+P4uyNar5LI+S+QIFN7om9RIQP/hiKbc+OgLu9GLlldXj84+P4Z9IVupMNISZGgU265JEQTxx4ZTymhnqjWcfwr+QczPj4OHJKa/kujRCLRYFNuszZ1hqbnn4AG2cPg6ONqOXyv38fxZbDV+kTkoSYAAU26bZHw3xw4NXxmNDfHZomHf7xczYe/egYThdW8V0aIRaFApsYhaeDBJ/PG4nVM4bC0UaEiyVKzPj4ON7cfRZVdHMEQoyCApsYDcdxeGqUP35dMgFPDO8DoOW67Uc+TMGuk4XQ6Wj2P0K6gwKbGJ2rnRhrnwjDty9EIsTLHlUqLd7YfQ5/3HwcF4uVfJdHiNmiwCYmM1Lmgp/+OhZvTx0IW2shThdWY9q/j2DFTxdQ26jluzxCzA4FNjEpkVCA58cFInnJQ5ga6g0dA7YfK8DED1Px42/FdJMEQu4BBTbpEV6OEmx6+gF88dwoBLjZoqxWjZe/PoM/fZZOwySEdBIFNulR4/u7I/GVcVgyqT/EVgIcy1Vg6r+P4OWvzyCf7tpOSIcosEmPE1sJ8deJ/ZD06gT8IcwHjAE//laMqPWpiN9zDiU1DXyXSEivRIFNeOPvKsW/Zw/D/pfH4pEQDzTrGL7OKMSEtSl4b99FVNL124QYoMAmvBvs44htz47Ety9EYpTMBZomHbYezce4D37FP5Ou0BUlhNxEgU16jZEyF+z6y4P4fN5IDPZxQL2mGf9KzsH4NYew5fBVmnub3Pes+C6AkN/jOA4PDfDA+H7uSLwgx7oDl3G1vB7/+DkbW49cxWhXDuMam+AiEvFdKiE9jo6wSa8kEHCYMtQbB14ZjzV/DIWvkw1Ka9X4vkCIcWtTsfyH88grr+O7TEJ6FAU26dWshAI8OcIPv742ASv+MBCeNgz1mmbsSLuGiR+m4s+fpePXS6U0Twm5L9CQCDELYishnh7lB8fyc3AKicD/0m8g+VIpjuRU4EhOBfq6SjEnUoYnRvSBg4SGS4hlosAmZoXjgDFBrngoxAuFChX+e6IAu05exzWFCqv2XcSHBy5jxgO+eHa0DMEe9nyXS4hR0ZAIMVv+rlL8feognHhrIv7x+BD097SDStOM/50oRNT6w3hm6wnsP1sCTRPd/YZYhl4R2Js2bYJMJoNEIkFERAQyMjI63P7bb79FSEgIJBIJhg4dip9//tlg/bPPPguO4wy+YmNjTdkC4ZHU2grPRPTF/70yHl89H4HoQZ4QcMCxXAVe+uo0IhOSkfBLNgroo+/EzPEe2Lt27UJcXByWL1+O06dPIywsDDExMSgrK2t3++PHj2P27NmYP38+zpw5g+nTp2P69Ok4f/68wXaxsbEoKSnRf3399dc90Q7hEcdxGB3shk/njEDq0ofx10eC4WEvhqJeg/+kXsVD61LwzNYT2He2mI66iVnifQx7/fr1WLBgAebNmwcA2Lx5M/bv349t27bhzTffbLP9v/71L8TGxmLp0qUAgFWrViEpKQkfffQRNm/erN9OLBbDy8urUzWo1Wqo1Wr990ply+xxWq0WWq15fMqutU5zqbcr7qVHL3sRXn44EC+OlyHlSgV2nrqBwzkVOJarwLFcBVxsRZgxzBezRvhC5mpr6tI7hV5D82fqvngNbI1Gg8zMTMTHx+uXCQQCREVFIS0trd3npKWlIS4uzmBZTEwM9u7da7AsJSUFHh4ecHZ2xiOPPIL33nsPrq6u7e4zISEBK1asaLP8wIEDkEql99gVv5KSkvguweS60uMMV+AhO+BEqQAnyjhU1mux9WgBth4tQD8HHSI9GUJdGES8/5+TXkNzplKpTLp/XgO7oqICzc3N8PT0NFju6emJS5cutfscuVze7vZyuVz/fWxsLGbMmIGAgADk5eXhrbfewuTJk5GWlgahUNhmn/Hx8Qa/BJRKJfz8/BAdHQ0HB4futNhjtFotkpKSMGnSJIgs9FOAxujxTwCamnVI/d1Rd45SgBwlYC+xwpQhnpge7oPh/k7gOM64DdwFvYbmT6FQmHT/vA+JmMJTTz2lfzx06FCEhoYiKCgIKSkpmDhxYpvtxWIxxGJxm+Uikcjs3lTmWPO96m6PIhEQG+qL2FBfFFU3YNfJ69ideaPl8aki7DpVBH8XKWY84IsZw/rA37Vn/5dFr6H5MnVPvP4H0M3NDUKhEKWlpQbLS0tL7zj+7OXldU/bA0BgYCDc3NyQm5vb/aKJRfF1skHcpP448vrD+HrBg3hieB/YWgtRWKnChoM5GL/2EJ7YfBxfZxSipsEyx12J+eA1sK2trTF8+HAkJyfrl+l0OiQnJyMyMrLd50RGRhpsD7SMh91pewC4ceMGFAoFvL29jVM4sTgCAYfIIFesfSIMJ9+OwoZZ4RjXzw0CDjhZUIX4Pecw8h8H8dJXp/HrpVKom2jmQNLzeB8SiYuLw9y5czFixAiMGjUKGzZsQH19vf6qkTlz5sDX1xcJCQkAgL/97W+YMGECPvzwQ0ydOhU7d+7EqVOn8OmnnwIA6urqsGLFCsycORNeXl7Iy8vD66+/juDgYMTExPDWJzEfUmsrTB/mi+nDfCGvacTerCLszryBnLI67D9bgv1nS2BtJUC4nxMiAlwwKsAFD/g7w1bM+z8nYuF4f4fNmjUL5eXlWLZsGeRyOcLDw5GYmKg/sVhYWAiB4NZ/BEaPHo2vvvoKb7/9Nt566y3069cPe/fuxZAhQwAAQqEQZ8+exY4dO1BdXQ0fHx9ER0dj1apV7Y5TE9IRL0cJXpgQhL+MD8SFYiV2n76BfWdLUF6rRkZ+JTLyKwEAQgGHIT4OGClrCfCRMhc421rzXD2xNBxjjKY5u41SqYSjoyNqamrM6iqRn3/+GVOmTLHIkzlA7+mRMYarFfXIyK/EyfxKpOdXoqi67X0o+3vaYaTMBcP8ndHf0w7BHnaQWt/5GKm39GdKlt6jQqGAm5ubybKD9yNsQswNx3EIcrdDkLsdZo/yBwAUVTfgZH4lMgpajrpzy+pwpbTl68v0wpvPA/ycpejvaY/+nnY3/7RHoLstJKK2l5sScjsKbEKMwNfJBr43x70BQFGnxsmCKmTkV+JiSQ1ySuugqNegsFKFwkoVDmbfutJJwAEyN1sEu9tCoOTgfFWBkQHusLGmECeGKLAJMQFXOzFih3ghdsity00r6tS4UlqLnNI6XC6tRU5pLS7La6FsbMLV8npcLa8HIETi9kyIhBxC+zhh1M2TmiP6OsOe5vm+71FgE9JD3OzEcLMTY3SQm34ZYwxltWpcltfiUkkNEjOyUaS1QalSjcxrVci8VoVPUvIg4FruLt96VQqd1Lw/UWATwiOO4+DpIIGngwSRAU7wrL6AyZPHQ17bhPR8BdJvXolSWKnCuaIanCuqwdaj+QCAEC97jJS5YITMGaMCXODtaMNzN8TUKLAJ6WU4joO/qxT+rlI8McIPAFBS04CMm1ekpF9VIK+8Hpfktbgkr8V/T1wDAPRxtsEomQtGyFwwKsAZQe52PT4fCjEtCmxCzIC3ow0eC/fFY+EtJzUr6tT6q1JOFVThQnENblQ14EZVEfacKQIAOEtFLeEtc8HIABcM9LaH2IpOZJozCmxCzJCbnRiTh3pj8tCW6Rbq1E04U1ilD/Gs69WoUmmRdLEUSRdbrkjhOMDH0QYBbrbo6yq9+actAtyk8HORUpibAQpsQiyAndgK4/q5Y1w/dwCApkmH88U1OFVQiYz8Kpy6VolqlRZF1Q0oqm7A0dvmQbs9zPu6SuHlaANvRwm8HSXwsJfA2qoXTBZ+n6PAJsQCWVsJ8IC/Mx7wd8bC8S1Xo1TUaXBNUY/8inpcU6iQr6hHwc3HdeqmO4Y50BLobnZieDtK4OXQEuKtge7hIIbU2gpiK0HLl0h467GVECIhR2PpRkKBTch9gOM4uNuL4W4vxgiZi8G69sK8sFIFubIR8pqWL02zDuW1apTXqnEWNff4s6EPb7GVAIImIb6Sn4SbvQRuttZwtRPD1c4arrZiuNnd+t5ebEVBfxsKbELucx2FOdAS6JX1GpTUNKKkphHymoabf7Z8X1bbiEatDuomHdRNzVA36QxucswY0KjVoVHbuoyDPL/qrnVZCwVws7OGu4MEnvZieDiI4WnfckTv4SCBh70Yng4SuEitIRDcH8FOgU0I6RDHcTePesUY4uvYqefodAya5t+F+M1Ar2tQ40DqMQQPDkd1QzMU9Woo6jSoqNOgsl4NRb0GijoN6tRN0DTrUFzTiOKaxg5/lpWg5ReOi601hIKW4RcOLUf2HAABx9183LJAwLUssxNbwVlqDWdbazhLRXCWWsNJKoKLrTWcpC3LnKQt++wtKLAJIUYnEHCQCIQ3J7W69ZF6rVaMa44MU0K9O5ytr1HbjIo6NSrqNChVNqKsVo0yZSPKlGqU1rb8WVbbCEW9Bk06pj/6NwVHGxGcpSI4toa4TUuQO/0u5J2k1nCyEYGpLfgmvIQQ0h6JSIg+zlL0ce74fpraZh0q6tQoU6pRqdKAMQadDmBoGcrR/8lalwEMDM06BmVjE6rrNahSaVGt0qBSdetxVb0GysYmAEBNg7bl9nCKu4exjgKbEELaJxIK4O1oY5KP5Tc161DdcDPAVVpUq7SoUmlQrdLcfKxFTYMGVfVa/XYVVaY5ym9FgU0IIe2wEgr0E3Z1lkKhgNta09VEV8ITQoiZoMAmhBAzQYFNCCFmggKbEELMBAU2IYSYCQpsQggxE3RZXzsYYwAApVLJcyWdp9VqoVKpoFQqO/wEmTmz9B4tvT/A8nusra0FcCtDjI0Cux2tf+l+fn48V0IIMUcKhQKOjp2bd+VecMxUvwrMmE6nQ3FxMezt7c1mekelUgk/Pz9cv34dDg4OfJdjEpbeo6X3B1h+jzU1NfD390dVVRWcnJyMvn86wm6HQCBAnz59+C6jSxwcHCzyH8LvWXqPlt4fYPk9CgSmOT1IJx0JIcRMUGATQoiZoMC2EGKxGMuXL4dY3PmJasyNpfdo6f0Blt+jqfujk46EEGIm6AibEELMBAU2IYSYCQpsQggxExTYhBBiJiiwzcy7774LjuMMvkJCQvTrGxsb8dJLL8HV1RV2dnaYOXMmSktLeay4Y4cPH8Yf/vAH+Pj4gOM47N2712A9YwzLli2Dt7c3bGxsEBUVhZycHINtKisr8cwzz8DBwQFOTk6YP38+6urqerCLjt2tx2effbbNaxobG2uwTW/uMSEhASNHjoS9vT08PDwwffp0XL582WCbzrwvCwsLMXXqVEilUnh4eGDp0qVoamrqyVba1Zn+HnrooTav4QsvvGCwjTH6o8A2Q4MHD0ZJSYn+6+jRo/p1r776Kn766Sd8++23SE1NRXFxMWbMmMFjtR2rr69HWFgYNm3a1O76NWvWYOPGjdi8eTPS09Nha2uLmJgYNDbeutnpM888gwsXLiApKQn79u3D4cOHsXDhwp5q4a7u1iMAxMbGGrymX3/9tcH63txjamoqXnrpJZw4cQJJSUnQarWIjo5GfX29fpu7vS+bm5sxdepUaDQaHD9+HDt27MDnn3+OZcuW8dGSgc70BwALFiwweA3XrFmjX2e0/hgxK8uXL2dhYWHtrquurmYikYh9++23+mXZ2dkMAEtLS+uhCrsOAPv+++/13+t0Oubl5cXWrl2rX1ZdXc3EYjH7+uuvGWOMXbx4kQFgJ0+e1G/zyy+/MI7jWFFRUY/V3lm398gYY3PnzmWPPfbYHZ9jbj2WlZUxACw1NZUx1rn35c8//8wEAgGTy+X6bT755BPm4ODA1Gp1zzZwF7f3xxhjEyZMYH/729/u+Bxj9UdH2GYoJycHPj4+CAwMxDPPPIPCwkIAQGZmJrRaLaKiovTbhoSEwN/fH2lpaXyV22X5+fmQy+UG/Tg6OiIiIkLfT1paGpycnDBixAj9NlFRURAIBEhPT+/xmrsqJSUFHh4eGDBgABYtWgSFQqFfZ2491tTUAABcXFwAdO59mZaWhqFDh8LT01O/TUxMDJRKJS5cuNCD1d/d7f21+vLLL+Hm5oYhQ4YgPj4eKpVKv85Y/dHkT2YmIiICn3/+OQYMGICSkhKsWLEC48aNw/nz5yGXy2Ftbd1mljBPT0/I5XJ+Cu6G1pp//yZv/b51nVwuh4eHh8F6KysruLi4mE3PsbGxmDFjBgICApCXl4e33noLkydPRlpaGoRCoVn1qNPp8Morr2DMmDEYMmQIAHTqfSmXy9t9nVvX9Rbt9QcATz/9NPr27QsfHx+cPXsWb7zxBi5fvow9e/YAMF5/FNhmZvLkyfrHoaGhiIiIQN++ffHNN9/AxsaGx8pIVz311FP6x0OHDkVoaCiCgoKQkpKCiRMn8ljZvXvppZdw/vx5g/MqluRO/f3+fMLQoUPh7e2NiRMnIi8vD0FBQUb7+TQkYuacnJzQv39/5ObmwsvLCxqNBtXV1QbblJaWwsvLi58Cu6G15tuvJvh9P15eXigrKzNY39TUhMrKSrPsGQACAwPh5uaG3NxcAObT4+LFi7Fv3z4cOnTIYHrizrwvvby82n2dW9f1Bnfqrz0REREAYPAaGqM/CmwzV1dXh7y8PHh7e2P48OEQiURITk7Wr798+TIKCwsRGRnJY5VdExAQAC8vL4N+lEol0tPT9f1ERkaiuroamZmZ+m1+/fVX6HQ6/T8ac3Pjxg0oFAp4e3sD6P09MsawePFifP/99/j1118REBBgsL4z78vIyEicO3fO4BdTUlISHBwcMGjQoJ5p5A7u1l97srKyAMDgNTRKf104SUp4tGTJEpaSksLy8/PZsWPHWFRUFHNzc2NlZWWMMcZeeOEF5u/vz3799Vd26tQpFhkZySIjI3mu+s5qa2vZmTNn2JkzZxgAtn79enbmzBl27do1xhhjq1evZk5OTuyHH35gZ8+eZY899hgLCAhgDQ0N+n3ExsayYcOGsfT0dHb06FHWr18/Nnv2bL5aaqOjHmtra9lrr73G0tLSWH5+Pjt48CB74IEHWL9+/VhjY6N+H725x0WLFjFHR0eWkpLCSkpK9F8qlUq/zd3el01NTWzIkCEsOjqaZWVlscTERObu7s7i4+P5aMnA3frLzc1lK1euZKdOnWL5+fnshx9+YIGBgWz8+PH6fRirPwpsMzNr1izm7e3NrK2tma+vL5s1axbLzc3Vr29oaGAvvvgic3Z2ZlKplD3++OOspKSEx4o7dujQIQagzdfcuXMZYy2X9r3zzjvM09OTicViNnHiRHb58mWDfSgUCjZ79mxmZ2fHHBwc2Lx581htbS0P3bSvox5VKhWLjo5m7u7uTCQSsb59+7IFCxYYXP7FWO/usb3eALDt27frt+nM+7KgoIBNnjyZ2djYMDc3N7ZkyRKm1Wp7uJu27tZfYWEhGz9+PHNxcWFisZgFBwezpUuXspqaGoP9GKM/ml6VEELMBI1hE0KImaDAJoQQM0GBTQghZoICmxBCzAQFNiGEmAkKbEIIMRMU2IQQYiYosAkhxExQYBPSA1JSUsBxXJsJkAi5FxTYhBBiJiiwCSHETFBgk/uCTqdDQkICAgICYGNjg7CwMHz33XcAbg1X7N+/H6GhoZBIJHjwwQdx/vx5g33s3r0bgwcPhlgshkwmw4cffmiwXq1W44033oCfnx/EYjGCg4Px2WefGWyTmZmJESNGQCqVYvTo0W3uvk1Ih4wznxUhvdt7773HQkJCWGJiIsvLy2Pbt29nYrGYpaSk6GfTGzhwIDtw4AA7e/YsmzZtGpPJZEyj0TDGGDt16hQTCARs5cqV7PLly2z79u3MxsbGYEa6J598kvn5+bE9e/awvLw8dvDgQbZz507G2K0Z+yIiIlhKSgq7cOECGzduHBs9ejQffx3ETFFgE4vX2NjIpFIpO378uMHy+fPns9mzZ+vDtDVcGWuZztTGxobt2rWLMcbY008/zSZNmmTw/KVLl7JBgwYxxhi7fPkyA8CSkpLaraH1Zxw8eFC/bP/+/QyAwdzehHSEhkSIxcvNzYVKpcKkSZNgZ2en//riiy+Ql5en3+73d+VxcXHBgAEDkJ2dDQDIzs7GmDFjDPY7ZswY5OTkoLm5GVlZWRAKhZgwYUKHtYSGhuoft96N5PbbfxFyJ3QTXmLx6urqAAD79++Hr6+vwTqxWGwQ2l3V2Rsgi0Qi/WOO4wC0jK8T0hl0hE0s3qBBgyAWi1FYWIjg4GCDLz8/P/12J06c0D+uqqrClStXMHDgQADAwIEDcezYMYP9Hjt2DP3794dQKMTQoUOh0+mQmpraM02R+xIdYROLZ29vj9deew2vvvoqdDodxo4di5qaGhw7dgwODg7o27cvAGDlypVwdXWFp6cn/v73v8PNzQ3Tp08HACxZsgQjR47EqlWrMGvWLKSlpeGjjz7Cxx9/DACQyWSYO3cunnvuOWzcuBFhYWG4du0aysrK8OSTT/LVOrE0fA+iE9ITdDod27BhAxswYAATiUTM3d2dxcTEsNTUVP0JwZ9++okNHjyYWVtbs1GjRrHffvvNYB/fffcdGzRoEBOJRMzf35+tXbvWYH1DQwN79dVX9ffcDA4OZtu2bWOM3TrpWFVVpd++9aa8+fn5pm6fWAi6pyO576WkpODhhx9GVVUVnJyc+C6HkDuiMWxCCDETFNiEEGImaEiEEELMBB1hE0KImaDAJoQQM0GBTQghZoICmxBCzAQFNiGEmAkKbEIIMRMU2IQQYiYosAkhxEz8P+9Q9Vaa6S7xAAAAAElFTkSuQmCC\n","text/plain":["\u003cFigure size 350x250 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n","batch_size, num_steps = 64, 10\n","lr, num_epochs, device = 0.005, 250, try_gpu()\n","\n","train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n","encoder = Seq2SeqEncoder(\n","    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n","decoder = Seq2SeqAttentionDecoder(\n","    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n","net = EncoderDecoder(encoder, decoder)\n","train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":651,"status":"ok","timestamp":1693104255061,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"fwF9EWXcS90v","outputId":"7ae9a0c1-cfd8-4ed1-da4a-db7ccfd371bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["go . =\u003e va !,  bleu 1.000\n","i lost . =\u003e je suis partie .,  bleu 0.000\n","he's calm . =\u003e il est malade .,  bleu 0.658\n","i'm home . =\u003e je suis chez moi .,  bleu 1.000\n"]}],"source":["engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n","fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n","for eng, fra in zip(engs, fras):\n","    translation, dec_attention_weight_seq = predict_seq2seq(\n","        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n","    print(f'{eng} =\u003e {translation}, ',\n","          f'bleu {bleu(translation, fra, k=2):.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1c19i4jMrecp"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jjk--LS8-OzT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_C3u10jR97OH"},"outputs":[],"source":["# 多头注意力机制\n","class MultiHeadAttention(nn.Module):\n","    \"\"\"多头注意力\"\"\"\n","    def __init__(self, key_size, query_size, value_size, num_hiddens,\n","                 num_heads, dropout, bias=False, **kwargs):\n","        super(MultiHeadAttention, self).__init__(**kwargs)\n","        self.num_heads = num_heads\n","        self.attention = DotProductAttention(dropout)\n","        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n","        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n","        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n","        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n","\n","    def forward(self, queries, keys, values, valid_lens):\n","        # queries，keys，values的形状:\n","        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n","        # valid_lens　的形状:\n","        # (batch_size，)或(batch_size，查询的个数)\n","        # 经过变换后，输出的queries，keys，values　的形状:\n","        # (batch_size*num_heads，查询或者“键－值”对的个数，\n","        # num_hiddens/num_heads)\n","        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n","        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n","        values = transpose_qkv(self.W_v(values), self.num_heads)\n","\n","        if valid_lens is not None:\n","            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n","            # 然后如此复制第二项，然后诸如此类。\n","            valid_lens = torch.repeat_interleave(\n","                valid_lens, repeats=self.num_heads, dim=0)\n","\n","        # output的形状:(batch_size*num_heads，查询的个数，\n","        # num_hiddens/num_heads)\n","        output = self.attention(queries, keys, values, valid_lens)\n","\n","        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n","        output_concat = transpose_output(output, self.num_heads)\n","        return self.W_o(output_concat)\n","\n","def transpose_qkv(X, num_heads):\n","    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n","    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n","    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n","    # num_hiddens/num_heads)\n","    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n","\n","    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n","    # num_hiddens/num_heads)\n","    X = X.permute(0, 2, 1, 3)\n","\n","    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n","    # num_hiddens/num_heads)\n","    return X.reshape(-1, X.shape[2], X.shape[3])\n","\n","\n","\n","def transpose_output(X, num_heads):\n","    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n","    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n","    X = X.permute(0, 2, 1, 3)\n","    return X.reshape(X.shape[0], X.shape[1], -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mD2mDnwryXHi"},"outputs":[],"source":["# 10.7 Transformer\n","import math\n","import pandas as pd\n","import torch\n","from torch import nn\n","\n","# 基于位置的前馈网络\n","class PositionWiseFFN(nn.Module):\n","    \"\"\"基于位置的前馈网络\"\"\"\n","    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n","                 **kwargs):\n","        super(PositionWiseFFN, self).__init__(**kwargs)\n","        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n","        self.relu = nn.ReLU()\n","        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n","\n","    def forward(self, X):\n","        return self.dense2(self.relu(self.dense1(X)))\n","\n","class AddNorm(nn.Module):\n","    \"\"\"残差连接后进行层规范化\"\"\"\n","    def __init__(self, normalized_shape, dropout, **kwargs):\n","        super(AddNorm, self).__init__(**kwargs)\n","        self.dropout = nn.Dropout(dropout)\n","        self.ln = nn.LayerNorm(normalized_shape)\n","\n","    def forward(self, X, Y):\n","        return self.ln(self.dropout(Y) + X)\n","\n","class PositionalEncoding(nn.Module):\n","    \"\"\"位置编码\"\"\"\n","    def __init__(self, num_hiddens, dropout, max_len=1000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        # 创建一个足够长的P\n","        self.P = torch.zeros((1, max_len, num_hiddens))\n","        X = torch.arange(max_len, dtype=torch.float32).reshape(\n","            -1, 1) / torch.pow(10000, torch.arange(\n","            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n","        self.P[:, :, 0::2] = torch.sin(X)\n","        self.P[:, :, 1::2] = torch.cos(X)\n","\n","    def forward(self, X):\n","        X = X + self.P[:, :X.shape[1], :].to(X.device)\n","        return self.dropout(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQDrP35mz_Ez"},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","  def __init__(self, key_size, query_size, value_size, num_hiddens,\n","                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n","                 dropout, use_bias=False, **kwargs):\n","    super(EncoderBlock, self).__init__(**kwargs)\n","    self.attention = MultiHeadAttention(\n","        key_size, query_size, value_size, num_hiddens, num_heads, dropout\n","    )\n","    self.addnorm1 = AddNorm(norm_shape, dropout)\n","    self.ffn = PositionWiseFFN(\n","        ffn_num_input, ffn_num_hiddens, num_hiddens\n","    )\n","    self.addnorm2 = AddNorm(norm_shape, dropout)\n","\n","  def forward(self, X, valid_lens):\n","    Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n","    return self.addnorm2(Y, self.ffn(Y))\n","\n","class TransformerEncoder(Encoder):\n","    \"\"\"Transformer编码器\"\"\"\n","    def __init__(self, vocab_size, key_size, query_size, value_size,\n","                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n","                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n","        super(TransformerEncoder, self).__init__(**kwargs)\n","        self.num_hiddens = num_hiddens\n","        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n","        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n","        self.blks = nn.Sequential()\n","        for i in range(num_layers):\n","            self.blks.add_module(\"block\"+str(i),\n","                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n","                             norm_shape, ffn_num_input, ffn_num_hiddens,\n","                             num_heads, dropout, use_bias))\n","\n","    def forward(self, X, valid_lens, *args):\n","        # 因为位置编码值在-1和1之间，\n","        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n","        # 然后再与位置编码相加。\n","        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n","        self.attention_weights = [None] * len(self.blks)\n","        for i, blk in enumerate(self.blks):\n","            X = blk(X, valid_lens)\n","            self.attention_weights[\n","                i] = blk.attention.attention.attention_weights\n","        return X\n","\n","class DecoderBlock(nn.Module):\n","    \"\"\"解码器中第i个块\"\"\"\n","    def __init__(self, key_size, query_size, value_size, num_hiddens,\n","                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n","                 dropout, i, **kwargs):\n","        super(DecoderBlock, self).__init__(**kwargs)\n","        self.i = i\n","        self.attention1 = MultiHeadAttention(\n","            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n","        self.addnorm1 = AddNorm(norm_shape, dropout)\n","        self.attention2 = MultiHeadAttention(\n","            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n","        self.addnorm2 = AddNorm(norm_shape, dropout)\n","        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n","                                   num_hiddens)\n","        self.addnorm3 = AddNorm(norm_shape, dropout)\n","\n","    def forward(self, X, state):\n","        enc_outputs, enc_valid_lens = state[0], state[1]\n","        # 训练阶段，输出序列的所有词元都在同一时间处理，\n","        # 因此state[2][self.i]初始化为None。\n","        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n","        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n","        if state[2][self.i] is None:\n","            key_values = X\n","        else:\n","            key_values = torch.cat((state[2][self.i], X), axis=1)\n","        state[2][self.i] = key_values\n","        if self.training:\n","            batch_size, num_steps, _ = X.shape\n","            # dec_valid_lens的开头:(batch_size,num_steps),\n","            # 其中每一行是[1,2,...,num_steps]\n","            dec_valid_lens = torch.arange(\n","                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n","        else:\n","            dec_valid_lens = None\n","\n","        # 自注意力\n","        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n","        Y = self.addnorm1(X, X2)\n","        # 编码器－解码器注意力。\n","        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n","        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n","        Z = self.addnorm2(Y, Y2)\n","        return self.addnorm3(Z, self.ffn(Z)), state\n","\n","class TransformerDecoder(AttentionDecoder):\n","    def __init__(self, vocab_size, key_size, query_size, value_size,\n","                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n","                 num_heads, num_layers, dropout, **kwargs):\n","        super(TransformerDecoder, self).__init__(**kwargs)\n","        self.num_hiddens = num_hiddens\n","        self.num_layers = num_layers\n","        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n","        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n","        self.blks = nn.Sequential()\n","        for i in range(num_layers):\n","            self.blks.add_module(\"block\"+str(i),\n","                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n","                             norm_shape, ffn_num_input, ffn_num_hiddens,\n","                             num_heads, dropout, i))\n","        self.dense = nn.Linear(num_hiddens, vocab_size)\n","\n","    def init_state(self, enc_outputs, enc_valid_lens, *args):\n","        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n","\n","    def forward(self, X, state):\n","        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n","        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n","        for i, blk in enumerate(self.blks):\n","            X, state = blk(X, state)\n","            # 解码器自注意力权重\n","            self._attention_weights[0][\n","                i] = blk.attention1.attention.attention_weights\n","            # “编码器－解码器”自注意力权重\n","            self._attention_weights[1][\n","                i] = blk.attention2.attention.attention_weights\n","        return self.dense(X), state\n","\n","    @property\n","    def attention_weights(self):\n","        return self._attention_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":669,"status":"ok","timestamp":1693622098511,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"kPH1cQC806cW","outputId":"e226160f-d9a9-4c7f-f84c-a6e9c629f2ff"},"outputs":[{"data":{"text/plain":["torch.Size([2, 100, 24])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["X = torch.ones((2, 100, 24))\n","valid_lens = torch.tensor([3, 2])\n","encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n","encoder_blk.eval()\n","encoder_blk(X, valid_lens).shape\n","encoder = TransformerEncoder(\n","    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n","encoder.eval()\n","encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"elapsed":55424,"status":"ok","timestamp":1693625731342,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"kHHyJp_f_JTK","outputId":"ce2e8911-ef3b-4cf1-e979-34331bb7c529"},"outputs":[{"name":"stdout","output_type":"stream","text":["loss 0.032, 8670.9 tokens/sec on cuda:0\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 350x250 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n","lr, num_epochs, device = 0.005, 200, try_gpu()\n","ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n","key_size, query_size, value_size = 32, 32, 32\n","norm_shape = [32]\n","\n","train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n","\n","encoder = TransformerEncoder(\n","    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n","    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n","    num_layers, dropout)\n","decoder = TransformerDecoder(\n","    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n","    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n","    num_layers, dropout)\n","net = EncoderDecoder(encoder, decoder)\n","train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":374,"status":"ok","timestamp":1693625734518,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"Fhr7ldOu4tVI","outputId":"13c600bf-b1a7-4b89-955c-d36157cf747d"},"outputs":[{"name":"stdout","output_type":"stream","text":["go . =\u003e va !,  bleu 1.000\n","i lost . =\u003e j'ai perdu .,  bleu 1.000\n","he's calm . =\u003e il est calme .,  bleu 1.000\n","i'm home . =\u003e je suis chez moi .,  bleu 1.000\n"]}],"source":["engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n","fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n","for eng, fra in zip(engs, fras):\n","    translation, dec_attention_weight_seq = predict_seq2seq(\n","        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n","    print(f'{eng} =\u003e {translation}, ',\n","          f'bleu {bleu(translation, fra, k=2):.3f}')"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":399,"status":"ok","timestamp":1693879591285,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"Cl-_NFxezxy_"},"outputs":[],"source":["import numpy as np\n","\n","def sift(li, low, high):\n","  temp = li[low]\n","  i = low\n","  j = 2 * i + 1\n","  while i \u003c= high:\n","    if j + 1 \u003c= high and li[j] \u003c li[j+1]:\n","      j += 1\n","    if j \u003c= high and li[j] \u003e temp:\n","      li[i] = li[j]\n","      i = j\n","      j = 2 * i + 1\n","    else:\n","      break\n","    print(li, i)\n","  li[i] = temp\n","  print(li)\n","\n","def topk(data, k):\n","  for"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693879592623,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"DELjF4JMnAvV","outputId":"a523a6ff-786a-409d-c5fb-e05e80654e52"},"outputs":[{"name":"stdout","output_type":"stream","text":["[8, 7, 8, 5, 3, 7, 2, 4, 3, 9] 2\n","[8, 7, 7, 5, 3, 7, 2, 4, 3, 9] 5\n","[8, 7, 7, 5, 3, 2, 2, 4, 3, 9]\n"]}],"source":["x = [2, 7, 8, 5, 3, 7, 2, 4, 3, 9]\n","sift(x, 0, 7)"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":391,"status":"ok","timestamp":1693886566213,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"eqIbE9EXzz-0"},"outputs":[],"source":["def merge(li, low, mid, high):\n","  lp, rp = low, mid + 1\n","  temp = []\n","  while lp \u003c= mid and rp \u003c= high:\n","    if li[lp] \u003c= li[rp]:\n","      temp.append(li[lp])\n","      lp += 1\n","    else:\n","      temp.append(li[rp])\n","      rp += 1\n","    # print(rp, lp)\n","  while lp \u003c= mid:\n","    temp.append(li[lp])\n","    lp += 1\n","  while rp \u003c= high:\n","    temp.append(li[rp])\n","    rp += 1\n","  li[low:high+1] = temp\n","  # print(li)\n","\n","def merge_sort(li, low, high):\n","  if low \u003c high:\n","    print(low, high)\n","    mid = (high-low)//2\n","    merge_sort(li, low, mid)\n","    merge_sort(li, mid+1, high)\n","    merge(li, low, mid, high)\n","    print(li)\n","\n"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693885777786,"user":{"displayName":"li jinnan","userId":"16912119366016895308"},"user_tz":300},"id":"xvCz5m6ecEU6","outputId":"c3435299-32a7-4838-c586-bb285d17fd47"},"outputs":[{"name":"stdout","output_type":"stream","text":["6 1\n","7 1\n","7 2\n","8 2\n","8 3\n","8 4\n","9 4\n","10 4\n","10 5\n","11 5\n","[1, 2, 3, 3, 4, 5, 5, 6, 8, 9, 10]\n"]}],"source":["merge([1, 3, 4, 5, 8, 10, 2, 3, 5, 6, 9], 0, 5, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ocjTb5BccJ2C"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 9\n","0 4\n","0 2\n","0 1\n","[2, 7, 8, 5, 3, 7, 2, 4, 3, 9]\n","[2, 7, 8, 5, 3, 7, 2, 4, 3, 9]\n","3 4\n","1 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n","2 4\n"]},{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","RecursionError: maximum recursion depth exceeded while calling a Python object\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-46-4368d40884b7\u003e\", line 2, in \u003ccell line: 2\u003e\n","    merge_sort(x, 0, 9)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 25, in merge_sort\n","    merge_sort(li, low, mid)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 26, in merge_sort\n","    merge_sort(li, mid+1, high)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 26, in merge_sort\n","    merge_sort(li, mid+1, high)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 26, in merge_sort\n","    merge_sort(li, mid+1, high)\n","  [Previous line repeated 950 more times]\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 23, in merge_sort\n","    print(low, high)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 402, in write\n","    self.pub_thread.schedule(lambda : self._buffer.write(string))\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 200, in schedule\n","    if self.thread.is_alive():\n","  File \"/usr/lib/python3.10/threading.py\", line 1180, in is_alive\n","    self._wait_for_tstate_lock(False)\n","  File \"/usr/lib/python3.10/threading.py\", line 1120, in _wait_for_tstate_lock\n","    if lock.locked():\n","RecursionError: maximum recursion depth exceeded while calling a Python object\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'RecursionError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 869, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","RecursionError: maximum recursion depth exceeded while calling a Python object\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-46-4368d40884b7\u003e\", line 2, in \u003ccell line: 2\u003e\n","    merge_sort(x, 0, 9)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 25, in merge_sort\n","    merge_sort(li, low, mid)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 26, in merge_sort\n","    merge_sort(li, mid+1, high)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 26, in merge_sort\n","    merge_sort(li, mid+1, high)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 26, in merge_sort\n","    merge_sort(li, mid+1, high)\n","  [Previous line repeated 950 more times]\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 23, in merge_sort\n","    print(low, high)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 402, in write\n","    self.pub_thread.schedule(lambda : self._buffer.write(string))\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 200, in schedule\n","    if self.thread.is_alive():\n","  File \"/usr/lib/python3.10/threading.py\", line 1180, in is_alive\n","    self._wait_for_tstate_lock(False)\n","  File \"/usr/lib/python3.10/threading.py\", line 1120, in _wait_for_tstate_lock\n","    if lock.locked():\n","RecursionError: maximum recursion depth exceeded while calling a Python object\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'RecursionError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 381, in find_recursion\n","    if not is_recursion_error(etype, value, records):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 368, in is_recursion_error\n","    and len(records) \u003e _FRAME_RECURSION_LIMIT\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 869, in getmodule\n","    if ismodule(module) and hasattr(module, '__file__'):\n","  File \"/usr/lib/python3.10/inspect.py\", line 182, in ismodule\n","    def ismodule(object):\n","KeyboardInterrupt\n"]},{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","RecursionError: maximum recursion depth exceeded while calling a Python object\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-46-4368d40884b7\u003e\", line 2, in \u003ccell line: 2\u003e\n","    merge_sort(x, 0, 9)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 25, in merge_sort\n","    merge_sort(li, low, mid)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 26, in merge_sort\n","    merge_sort(li, mid+1, high)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 26, in merge_sort\n","    merge_sort(li, mid+1, high)\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 26, in merge_sort\n","    merge_sort(li, mid+1, high)\n","  [Previous line repeated 950 more times]\n","  File \"\u003cipython-input-45-218561f435e2\u003e\", line 23, in merge_sort\n","    print(low, high)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 402, in write\n","    self.pub_thread.schedule(lambda : self._buffer.write(string))\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 200, in schedule\n","    if self.thread.is_alive():\n","  File \"/usr/lib/python3.10/threading.py\", line 1180, in is_alive\n","    self._wait_for_tstate_lock(False)\n","  File \"/usr/lib/python3.10/threading.py\", line 1120, in _wait_for_tstate_lock\n","    if lock.locked():\n","RecursionError: maximum recursion depth exceeded while calling a Python object\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'RecursionError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 381, in find_recursion\n","    if not is_recursion_error(etype, value, records):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 368, in is_recursion_error\n","    and len(records) \u003e _FRAME_RECURSION_LIMIT\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 381, in find_recursion\n","    if not is_recursion_error(etype, value, records):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 368, in is_recursion_error\n","    and len(records) \u003e _FRAME_RECURSION_LIMIT\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1624, in getframeinfo\n","    lines, lnum = findsource(frame)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 170, in findsource\n","    file = getsourcefile(object) or getfile(object)\n","  File \"/usr/lib/python3.10/inspect.py\", line 820, in getsourcefile\n","    if any(filename.endswith(s) for s in all_bytecode_suffixes):\n","KeyboardInterrupt\n"]}],"source":["x = [2, 7, 8, 5, 3, 7, 2, 4, 3, 9]\n","merge_sort(x, 0, 9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCj2QmRYfHrl"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNti3JG545Lnf75r2aoSlmW","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}