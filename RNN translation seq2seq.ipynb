{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOt9SBLldpXsnixbaLqIemS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nNqahEQqLHXr","executionInfo":{"status":"ok","timestamp":1691890926333,"user_tz":300,"elapsed":24073,"user":{"displayName":"li jinnan","userId":"16912119366016895308"}},"outputId":"b6a89950-eb02-4ca9-c645-d8234fadff88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEDeUeNBxnAT"},"outputs":[],"source":["# train_ch6所需的所有组件\n","import torch\n","from torch import nn\n","from IPython import display\n","import matplotlib.pyplot as plt\n","import time\n","import numpy as np\n","%matplotlib inline\n","import torchvision\n","from torch.utils import data\n","from torchvision import transforms\n","\n","def load_array(data_arrays, batch_size, is_train=True):\n","    dataset = data.TensorDataset(*data_arrays)\n","    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n","\n","# 更新器\n","def sgd(params, lr, batch):\n","    with torch.no_grad():\n","        for param in params:\n","            param -= lr * param.grad / batch_size\n","            param.grad.zero_()\n","\n","# 计时器\n","class Timer:\n","    def __init__(self):\n","        self.times = []\n","        self.start()\n","\n","    def start(self):\n","        self.tik = time.time()\n","\n","    def stop(self):\n","        self.times.append(time.time()-self.tik)\n","        return self.times[-1]\n","\n","    def avg(self):\n","        return sum(self.times)/len(self.times)\n","\n","    def sum(self):\n","        return sum(self.times)\n","\n","    def cumsum(self):\n","        return np.array(self.times).cumsum().tolist()\n","\n","\n","# 精准度的计算\n","def accuracy(y_hat, y):\n","    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n","        y_hat = y_hat.argmax(axis=1)\n","    cmp = y_hat.type(y.dtype) == y\n","    return float(cmp.type(y.dtype).sum())\n","\n","def evaluate_accuracy_gpu(net, data_iter, device=None):\n","    if isinstance(net, torch.nn.Module):\n","        net.eval()\n","        if not device:\n","          device = next(iter(net.parameters())).device\n","    metric = Accumulator(2)\n","    with torch.no_grad():\n","        for X, y in data_iter:\n","            if isinstance(X, list):\n","              # BERT微调所需\n","              X = [x.to(device) for x in X]\n","            else:\n","              X = X.to(device)\n","            y = y.to(device)\n","            metric.add(accuracy(net(X), y), y.numel())\n","    return metric[0] / metric[1]\n","\n","# 参数储存器\n","class Accumulator:\n","    def __init__(self, n):\n","        self.data = [0.0] * n\n","\n","    def add(self, *args):\n","        self.data = [a + float(b) for a, b in zip(self.data, args)]\n","\n","    def reset(self):\n","        self.data = [0.0] * len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","# 画图部分\n","def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n","    \"\"\"Set the axes for matplotlib.\"\"\"\n","    axes.set_xlabel(xlabel)\n","    axes.set_ylabel(ylabel)\n","    axes.set_xscale(xscale)\n","    axes.set_yscale(yscale)\n","    axes.set_xlim(xlim)\n","    axes.set_ylim(ylim)\n","    if legend:\n","        axes.legend(legend)\n","    axes.grid()\n","\n","class Animator:\n","    \"\"\"在动画中绘制数据\"\"\"\n","    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n","                 ylim=None, xscale='linear', yscale='linear',\n","                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n","                 figsize=(3.5, 2.5)):\n","        # 增量地绘制多条线\n","        if legend is None:\n","            legend = []\n","        # d2l.use_svg_display()\n","        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n","        if nrows * ncols == 1:\n","            self.axes = [self.axes, ]\n","        # 使用lambda函数捕获参数\n","        self.config_axes = lambda: set_axes(\n","            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n","        self.X, self.Y, self.fmts = None, None, fmts\n","\n","    def add(self, x, y):\n","        # 向图表中添加多个数据点\n","        if not hasattr(y, \"__len__\"):\n","            y = [y]\n","        n = len(y)\n","        if not hasattr(x, \"__len__\"):\n","            x = [x] * n\n","        if not self.X:\n","            self.X = [[] for _ in range(n)]\n","        if not self.Y:\n","            self.Y = [[] for _ in range(n)]\n","        for i, (a, b) in enumerate(zip(x, y)):\n","            if a is not None and b is not None:\n","                self.X[i].append(a)\n","                self.Y[i].append(b)\n","        self.axes[0].cla()\n","        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n","            self.axes[0].plot(x, y, fmt)\n","        self.config_axes()\n","        display.display(self.fig)\n","        display.clear_output(wait=True)\n","\n","# mini-batch取数据\n","def get_dataloader_workers():\n","  #使用四个线程\n","    return 4\n","\n","def load_data_fashion_mnist(batch_size, resize=None):\n","    trans = [transforms.ToTensor()]\n","    if resize:\n","        trans.insert(0, transforms.Resize(resize))\n","    trans = transforms.Compose(trans)\n","    mnist_train = torchvision.datasets.FashionMNIST(\n","        root=\"../data\", train=True, transform=trans, download=True)\n","    mnist_test = torchvision.datasets.FashionMNIST(\n","        root=\"../data\", train=False, transform=trans, download=True)\n","    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n","                            num_workers=get_dataloader_workers()), data.DataLoader(mnist_test, batch_size, shuffle=False,\n","                num_workers=get_dataloader_workers()))\n","\n","def try_gpu(i=0):\n","  \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n","  if torch.cuda.device_count() >= i + 1:\n","        return torch.device(f'cuda:{i}')\n","  return torch.device('cpu')\n","\n","\n","  # 训练\n","def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n","    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n","    def init_weights(m):\n","        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n","            nn.init.xavier_uniform_(m.weight)\n","    net.apply(init_weights)\n","    print('training on', device)\n","    net.to(device)\n","    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n","    loss = nn.CrossEntropyLoss()\n","    animator = Animator(xlabel='epoch', xlim=[1, num_epochs],\n","                            legend=['train loss', 'train acc', 'test acc'])\n","    timer, num_batches = Timer(), len(train_iter)\n","    for epoch in range(num_epochs):\n","        # 训练损失之和，训练准确率之和，样本数\n","        metric = Accumulator(3)\n","        net.train()\n","        for i, (X, y) in enumerate(train_iter):\n","            timer.start()\n","            optimizer.zero_grad()\n","            X, y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","            l = loss(y_hat, y)\n","            l.backward()\n","            optimizer.step()\n","            with torch.no_grad():\n","                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n","            timer.stop()\n","            train_l = metric[0] / metric[2]\n","            train_acc = metric[1] / metric[2]\n","            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n","                animator.add(epoch + (i + 1) / num_batches,\n","                             (train_l, train_acc, None))\n","        test_acc = evaluate_accuracy_gpu(net, test_iter)\n","        animator.add(epoch + 1, (None, None, test_acc))\n","    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n","          f'test acc {test_acc:.3f}')\n","    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n","          f'on {str(device)}')"]},{"cell_type":"code","source":["# 文本处理组件\n","import torch\n","# from d2l import torch as d2l\n","import collections\n","import re\n","# from d2l import torch as d2l\n","\n","class Vocab:\n","    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n","        if tokens==None:\n","            tokens = []\n","        if reserved_tokens==None:\n","            reserved_tokens = []\n","#         按出现频率排序\n","        counter = count_corpus(tokens)\n","        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n","                                  reverse=True)\n","        self.idx_to_token = ['<unk>'] + reserved_tokens\n","        self.token_to_idx = {token: idx for idx, token in\n","                           enumerate(self.idx_to_token)}\n","        for token, freq in self._token_freqs:\n","            if freq < min_freq:\n","                break\n","            if token not in self.token_to_idx:\n","                self.idx_to_token.append(token)\n","                self.token_to_idx[token] = len(self.idx_to_token) - 1\n","\n","    def __len__(self):\n","        return len(self.idx_to_token)\n","\n","    def __getitem__(self, tokens):\n","        if not isinstance(tokens, (list, tuple)):\n","            return self.token_to_idx.get(tokens, self.unk)\n","        return [self.__getitem__(token) for token in tokens]\n","\n","    def to_tokens(self, indices):\n","        if not isinstance(indices, (list, tuple)):\n","            return self.idx_to_token[indices]\n","        return [self.idx_to_token[index] for index in indices]\n","\n","    @property\n","    def unk(self):\n","        return 0\n","\n","    @property\n","    def token_freqs(self):\n","        return self._token_freqs\n","\n","\n","\n","def count_corpus(tokens):\n","    # 这里的tokens是1D列表或2D列表\n","    if len(tokens) == 0 or isinstance(tokens[0], list):\n","        tokens = [token for line in tokens for token in line]\n","    return collections.Counter(tokens)"],"metadata":{"id":"kcfcturaihwo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PMYp5naZLk9Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 语言模型和数据集\n","import random\n","import torch\n","\n","def seq_data_iter_random(corpus, batch_size, num_steps):\n","    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n","    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n","    corpus = corpus[random.randint(0, num_steps - 1):]\n","    # 减去1，是因为我们需要考虑标签\n","    num_subseqs = (len(corpus) - 1) // num_steps\n","    # 长度为num_steps的子序列的起始索引\n","    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n","    # 在随机抽样的迭代过程中，\n","    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n","    random.shuffle(initial_indices)\n","\n","    def data(pos):\n","        # 返回从pos位置开始的长度为num_steps的序列\n","        return corpus[pos: pos + num_steps]\n","\n","    num_batches = num_subseqs // batch_size\n","    for i in range(0, batch_size * num_batches, batch_size):\n","        # 在这里，initial_indices包含子序列的随机起始索引\n","        initial_indices_per_batch = initial_indices[i: i + batch_size]\n","        X = [data(j) for j in initial_indices_per_batch]\n","        Y = [data(j + 1) for j in initial_indices_per_batch]\n","        yield torch.tensor(X), torch.tensor(Y)\n","\n","def seq_data_iter_sequential(corpus, batch_size, num_steps):\n","    \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n","    # 从随机偏移量开始划分序列\n","    offset = random.randint(0, num_steps)\n","    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n","    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n","    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n","    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n","    num_batches = Xs.shape[1] // num_steps\n","    for i in range(0, num_steps * num_batches, num_steps):\n","        X = Xs[:, i: i + num_steps]\n","        Y = Ys[:, i: i + num_steps]\n","        yield X, Y\n","\n","class SeqDataLoader:\n","    \"\"\"加载序列数据的迭代器\"\"\"\n","    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n","        if use_random_iter:\n","            self.data_iter_fn = seq_data_iter_random\n","        else:\n","            self.data_iter_fn = seq_data_iter_sequential\n","        self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n","        self.batch_size, self.num_steps = batch_size, num_steps\n","\n","    def __iter__(self):\n","        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\n","\n","def load_data_time_machine(batch_size, num_steps,\n","                           use_random_iter=False, max_tokens=10000):\n","    \"\"\"返回时光机器数据集的迭代器和词表\"\"\"\n","    data_iter = SeqDataLoader(\n","        batch_size, num_steps, use_random_iter, max_tokens)\n","    return data_iter, data_iter.vocab"],"metadata":{"id":"ikp3H9Uwkfhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_ch8\n","%matplotlib inline\n","import math\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","\n","def predict_ch8(prefix, num_preds, net, vocab, device):\n","    \"\"\"在prefix后面生成新字符\"\"\"\n","    state = net.begin_state(batch_size=1, device=device)\n","    outputs = [vocab[prefix[0]]]\n","    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n","    for y in prefix[1:]:  # 预热期\n","        _, state = net(get_input(), state)\n","        outputs.append(vocab[y])\n","    for _ in range(num_preds):  # 预测num_preds步\n","        y, state = net(get_input(), state)\n","        outputs.append(int(y.argmax(dim=1).reshape(1)))\n","    return ''.join([vocab.idx_to_token[i] for i in outputs])\n","\n","def grad_clipping(net, theta):\n","    \"\"\"裁剪梯度\"\"\"\n","    if isinstance(net, nn.Module):\n","        params = [p for p in net.parameters() if p.requires_grad]\n","    else:\n","        params = net.params\n","    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n","    if norm > theta:\n","        for param in params:\n","            param.grad[:] *= theta / norm\n","\n","def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n","    \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\"\n","    state, timer = None, Timer()\n","    metric = Accumulator(2)  # 训练损失之和,词元数量\n","    for X, Y in train_iter:\n","        if state is None or use_random_iter:\n","            # 在第一次迭代或使用随机抽样时初始化state\n","            state = net.begin_state(batch_size=X.shape[0], device=device)\n","        else:\n","            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n","                # state对于nn.GRU是个张量\n","                state.detach_()\n","            else:\n","                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n","                for s in state:\n","                    s.detach_()\n","        y = Y.T.reshape(-1)\n","        X, y = X.to(device), y.to(device)\n","        y_hat, state = net(X, state)\n","        l = loss(y_hat, y.long()).mean()\n","        if isinstance(updater, torch.optim.Optimizer):\n","            updater.zero_grad()\n","            l.backward()\n","            grad_clipping(net, 1)\n","            updater.step()\n","        else:\n","            l.backward()\n","            grad_clipping(net, 1)\n","            # 因为已经调用了mean函数\n","            updater(batch_size=1)\n","        metric.add(l * y.numel(), y.numel())\n","    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n","\n","def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n","              use_random_iter=False):\n","    \"\"\"训练模型（定义见第8章）\"\"\"\n","    loss = nn.CrossEntropyLoss()\n","    animator = Animator(xlabel='epoch', ylabel='perplexity',\n","                            legend=['train'], xlim=[10, num_epochs])\n","    # 初始化\n","    if isinstance(net, nn.Module):\n","        updater = torch.optim.SGD(net.parameters(), lr)\n","    else:\n","        updater = lambda batch_size: sgd(net.params, lr, batch_size)\n","    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n","    # 训练和预测\n","    for epoch in range(num_epochs):\n","        ppl, speed = train_epoch_ch8(\n","            net, train_iter, loss, updater, device, use_random_iter)\n","        if (epoch + 1) % 10 == 0:\n","            print(predict('time traveller'))\n","            animator.add(epoch + 1, [ppl])\n","    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n","    print(predict('time traveller'))\n","    print(predict('traveller'))\n"],"metadata":{"id":"9UxXOAcHKFN7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QPi4fSMKMSN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 9.5 机器翻译与数据集\n","def read_data_nmt():\n","  with open('/content/drive/MyDrive/fra.txt', 'r', encoding='utf-8') as f:\n","    return f.read()\n","\n","def preprocess_nmt(text):\n","    \"\"\"预处理“英语－法语”数据集\"\"\"\n","    def no_space(char, prev_char):\n","        return char in set(',.!?') and prev_char != ' '\n","\n","    # 使用空格替换不间断空格\n","    # 使用小写字母替换大写字母\n","    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n","    # 在单词和标点符号之间插入空格\n","    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n","           for i, char in enumerate(text)]\n","    return ''.join(out)\n","\n","def tokenize_nmt(text, num_examples=None):\n","  source, target = [], []\n","  for i, line in enumerate(text.split('\\n')):\n","    if num_examples and i > num_examples:\n","      break\n","    parts = line.split('\\t')\n","    if len(parts) == 2:\n","      source.append(parts[0].split(' '))\n","      target.append(parts[1].split(' '))\n","  return source, target\n","\n","from matplotlib import pyplot as plt\n","def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n","    \"\"\"绘制列表长度对的直方图\"\"\"\n","    # plt.set_figsize()\n","    plt.figure(figsize=(8,5), dpi=80)\n","    _, _, patches = plt.hist(\n","        [[len(l) for l in xlist], [len(l) for l in ylist]])\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    for patch in patches[1].patches:\n","        patch.set_hatch('/')\n","    plt.legend(legend)\n","\n","def truncate_pad(line, num_steps, padding_token):\n","    \"\"\"截断或填充文本序列\"\"\"\n","    if len(line) > num_steps:\n","        return line[:num_steps]  # 截断\n","    return line + [padding_token] * (num_steps - len(line))  # 填充\n","\n","def build_array_nmt(lines, vocab, num_steps):\n","    \"\"\"将机器翻译的文本序列转换成小批量\"\"\"\n","    lines = [vocab[l] for l in lines]\n","    lines = [l + [vocab['<eos>']] for l in lines]\n","    array = torch.tensor([truncate_pad(\n","        l, num_steps, vocab['<pad>']) for l in lines])\n","    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n","    return array, valid_len\n","\n","def load_data_nmt(batch_size, num_steps, num_examples=600):\n","    \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n","    text = preprocess_nmt(read_data_nmt())\n","    source, target = tokenize_nmt(text, num_examples)\n","    src_vocab = Vocab(source, min_freq=2,\n","                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n","    tgt_vocab = Vocab(target, min_freq=2,\n","                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n","    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n","    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n","    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n","    data_iter = load_array(data_arrays, batch_size)\n","    return data_iter, src_vocab, tgt_vocab"],"metadata":{"id":"npKdmSt7NmN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 9.6 编码器-解码器架构\n","from torch import nn\n","\n","class Encoder(nn.Module):\n","  def __init__(self, **kwargs):\n","    super(Encoder, self).__init__(**kwargs)\n","\n","  def forward(self, X, *args):\n","    raise NotImplementedError\n","\n","class Decoder(nn.Module):\n","  def __init__(self, **kwargs):\n","    super(Decoder, self).__init__(**kwargs)\n","\n","  def init_state(self, enc_outputs, *args):\n","    raise NotImplementedError\n","\n","  def forward(self, X, state):\n","    raise NotImplementedError\n","\n","class EncoderDecoder(nn.Module):\n","  def __init__(self, encoder, decoder, **kwargs):\n","    super(EncoderDecoder, self).__init__(**kwargs)\n","    self.encoder = encoder\n","    self.decoder = decoder\n","\n","  def forward(self, enc_X, dec_X, *args):\n","    enc_outputs = self.encoder(enc_X, *args)\n","    dec_state = self.decoder.init_state(enc_outputs, *args)\n","    return self.decoder(dec_X, dec_state)"],"metadata":{"id":"BrGiox7lNLvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 9.7 seq2seq实现\n","class Seq2SeqEncoder(Encoder):\n","  def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n","               dropout=0, **kwargs):\n","    super(Seq2SeqEncoder, self).__init__(**kwargs)\n","    self.embedding = nn.Embedding(vocab_size, embed_size)\n","    self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)\n","\n","  def forward(self, X, *args):\n","    X = self.embedding(X).permute(1, 0, 2)\n","    output, state = self.rnn(X)\n","    return output, state\n","\n","class Seq2SeqDecoder(Decoder):\n","    \"\"\"用于序列到序列学习的循环神经网络解码器\"\"\"\n","    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n","                 dropout=0, **kwargs):\n","        super(Seq2SeqDecoder, self).__init__(**kwargs)\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n","                          dropout=dropout)\n","        self.dense = nn.Linear(num_hiddens, vocab_size)\n","\n","    def init_state(self, enc_outputs, *args):\n","        return enc_outputs[1]\n","\n","    def forward(self, X, state):\n","        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n","        X = self.embedding(X).permute(1, 0, 2)\n","        # 广播context，使其具有与X相同的num_steps\n","        context = state[-1].repeat(X.shape[0], 1, 1)\n","        X_and_context = torch.cat((X, context), 2)\n","        output, state = self.rnn(X_and_context, state)\n","        output = self.dense(output).permute(1, 0, 2)\n","        # output的形状:(batch_size,num_steps,vocab_size)\n","        # state的形状:(num_layers,batch_size,num_hiddens)\n","        return output, state\n","\n","def sequence_mask(X, valid_len, value=0):\n","    \"\"\"在序列中屏蔽不相关的项\"\"\"\n","    maxlen = X.size(1)\n","    mask = torch.arange((maxlen), dtype=torch.float32,\n","                        device=X.device)[None, :] < valid_len[:, None]\n","    X[~mask] = value\n","    return X\n","\n","class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n","    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n","    # pred的形状：(batch_size,num_steps,vocab_size)\n","    # label的形状：(batch_size,num_steps)\n","    # valid_len的形状：(batch_size,)\n","    def forward(self, pred, label, valid_len):\n","        weights = torch.ones_like(label)\n","        weights = sequence_mask(weights, valid_len)\n","        self.reduction='none'\n","        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n","            pred.permute(0, 2, 1), label)\n","        # print(unweighted_loss.shape)\n","        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n","        return weighted_loss\n","\n","def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n","  def xavier_init_weights(m):\n","    if type(m) == nn.Linear:\n","      nn.init.xavier_uniform_(m.weight)\n","    if type(m) == nn.GRU:\n","      for param in m._flat_weights_names:\n","        if \"weight\" in param:\n","          nn.init.xavier_uniform_(m._parameters[param])\n","\n","  net.apply(xavier_init_weights)\n","  net.to(device)\n","  optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","  loss = MaskedSoftmaxCELoss()\n","  net.train()\n","  animator = Animator(xlabel='epoch', ylabel='loss',\n","                     xlim=[10, num_epochs])\n","  for epoch in range(num_epochs):\n","    timer = Timer()\n","    metric = Accumulator(2)\n","    for batch in data_iter:\n","      optimizer.zero_grad()\n","      X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n","      bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n","                         device=device).reshape(-1, 1)\n","      dec_input = torch.cat([bos, Y[:, :-1]], 1)\n","      Y_hat, _ = net(X, dec_input, X_valid_len)\n","      l = loss(Y_hat, Y, Y_valid_len)\n","      l.sum().backward()\n","      grad_clipping(net, 1)\n","      num_tokens = Y_valid_len.sum()\n","      optimizer.step()\n","      with torch.no_grad():\n","        metric.add(l.sum(), num_tokens)\n","    if (epoch + 1) % 10 == 0:\n","            animator.add(epoch + 1, (metric[0] / metric[1],))\n","  print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n","        f'tokens/sec on {str(device)}')\n","\n","def predict_seq2seq(net, src_sentences, src_vocab, tgt_vocab,\n","                    num_steps, device, save_attention_weights=False):\n","  net.eval()\n","  src_tokens = src_vocab[src_sentences.lower().split(' ')] + [src_vocab['<eos>']]\n","  enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n","  src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n","  # 添加批量轴\n","  enc_X = torch.unsqueeze(\n","      torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0\n","  )\n","  enc_outputs = net.encoder(enc_X, enc_valid_len)\n","  dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n","  dec_X = torch.unsqueeze(\n","      torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0\n","  )\n","  output_seq, attention_weight_seq = [], []\n","  for _ in range(num_steps):\n","    Y, dec_state = net.decoder(dec_X, dec_state)\n","    dec_X = Y.argmax(dim=2)\n","    # print(f'shape of Y is {Y.shape}, shape of dec_X is {dec_X.shape}')\n","    pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n","    # print(f'pred is {pred},pred before is {dec_X.squeeze(dim=0).type(torch.int32)}')\n","    if save_attention_weights:\n","        attention_weight_seq.append(net.decoder.attention_weights)\n","        # 一旦序列结束词元被预测，输出序列的生成就完成了\n","    if pred == tgt_vocab['<eos>']:\n","        break\n","    output_seq.append(pred)\n","  return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n","\n","def bleu(pred_seq, label_seq, k):\n","    \"\"\"计算BLEU\"\"\"\n","    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n","    len_pred, len_label = len(pred_tokens), len(label_tokens)\n","    score = math.exp(min(0, 1 - len_label / len_pred))\n","    for n in range(1, k + 1):\n","        num_matches, label_subs = 0, collections.defaultdict(int)\n","        for i in range(len_label - n + 1):\n","            label_subs[' '.join(label_tokens[i: i + n])] += 1\n","        for i in range(len_pred - n + 1):\n","            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n","                num_matches += 1\n","                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n","        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n","    return score"],"metadata":{"id":"7_xuz_Y7F_bN","executionInfo":{"status":"ok","timestamp":1691892572798,"user_tz":300,"elapsed":490,"user":{"displayName":"li jinnan","userId":"16912119366016895308"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# 训练\n","embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n","batch_size, num_steps = 64, 10\n","lr, num_epochs, device = 0.005, 300, try_gpu()\n","\n","train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n","encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n","                        dropout)\n","decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n","                        dropout)\n","net = EncoderDecoder(encoder, decoder)\n","train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"id":"QnIm8gHskNF8","executionInfo":{"status":"ok","timestamp":1691892662078,"user_tz":300,"elapsed":28450,"user":{"displayName":"li jinnan","userId":"16912119366016895308"}},"outputId":"eab34196-c312-4943-e93d-cc5209872888"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["loss 0.019, 15252.3 tokens/sec on cuda:0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 350x250 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# 预测\n","engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n","fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n","for eng, fra in zip(engs, fras):\n","    translation, attention_weight_seq = predict_seq2seq(\n","        net, eng, src_vocab, tgt_vocab, num_steps, device)\n","    print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')"],"metadata":{"id":"QOPj98dGk_s9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691892666054,"user_tz":300,"elapsed":368,"user":{"displayName":"li jinnan","userId":"16912119366016895308"}},"outputId":"cf0e2ca3-1d74-4857-e6c3-34f1d757520f"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["go . => va !, bleu 1.000\n","i lost . => j'ai <unk> ., bleu 0.000\n","he's calm . => il est <unk> ., bleu 0.658\n","i'm home . => je suis <unk> de la tes gagné signe signe gagné, bleu 0.258\n"]}]}]}